% This is part of Giulietta
% Copyright (c) 2013-2015, 2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.


Here are the results which relate Lie groups and Lie algebras.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Lie algebra of a Lie group}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{propositionDef}      \label{DEFooKDCPooZOJsMD}
    If \( G\) is a Lie group, its tangent space on at the identity is a Lie algebra. 
    
    This is the \defe{Lie algebra}{Lie algebra of a Lie group} is is tangent space at identity. From a notational point of view, this is written
    \begin{equation}
        \lG=T_eG.
    \end{equation}
\end{propositionDef}

\begin{proof}
    We know from proposition \ref{PROPooOHLQooCNetuD} that \( T_eG\) is a vector space. We have to define a Lie bracket on it. For that we use the left-invariant vector field. Let \( X\in T_eG\) and \( g\in M\) we define
    \begin{equation}
        X^L_g=dL_gX
    \end{equation}
    where \( L_g\colon G\to G\) is the left translation: \( L_g(h)=gh\). If \( X,Y\in T_eG\) we define
    \begin{equation}
        [X,Y]=[X^L,Y^L]_e
    \end{equation}
    where the bracket on the right hand side is the commutator of vector field defined in \ref{DEFooHOTOooRaPwyo}. It defines a Lie algebra structure by the proposition \ref{PROPooSWQSooSEfTuX}.
\end{proof}

In order to make the notations clear, let us write the formula explicitly. If \( X,Y\in T_eG\) are given by \( X=\alpha'(0)\) and \( Y=\beta'(0)\) we have
\begin{subequations}        \label{SUBEQSooHKWMooQbeStl}
    \begin{align}
        (XY)f&=X(Y(f))\\
        &=\Dsdd{ (Yf)\big( \alpha(t) \big) }{t}{0}\\
        &=\Dsdd{ Y_{\alpha(t)}(f) }{t}{0}\\
        &=\Dsdd{ Y^L_{\alpha(t)}(f) }{t}{0}\\
        &=\DDsdd{ f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}.
    \end{align}
\end{subequations}

Now a great theorem without proof:
\begin{theorem} \label{tho:loc_isom}
Two Lie groups are locally isomorphic if and only if their Lie algebras are isomorphic.
\end{theorem}

\begin{theorem}		\label{ThoSubGpSubAlg}		\label{tho:gp_alg}
If $G$ is a Lie group, then
\begin{enumerate}
\item\label{ThoSubGpSubAlgi} if $\lH$ is the Lie algebra of a Lie subgroup $H$ of $G$, then it is a subalgebra of $\lG$,
\item Any subalgebra of $\lG$ is the Lie algebra of one and only one connected Lie subgroup of $G$.
\end{enumerate}

\begin{probleme}
Ã€ mon avis, il faut dire ``connexe et simplement connexe'', et non juste ``connexe''.
\end{probleme}

\end{theorem}
\begin{proof}

\subdem{First item}
Let $\dpt{i}{H}{G}$ be the identity map; it is a homomorphism from $H$ to $G$, thus $di_e$ is a homomorphism from $\lH$ to $\lG$. Conclusion: $\lH$ is a subalgebra of $\lG$.

\subdem{Characterization for $\lH$}
Before to go on with the second point, we derive an important characterization of $\lH$:
\begin{equation}\label{eq:path_alg}
\lH=\{X\in\lG:\text{the map } t\to\exp tX\text{ is a path in $H$}\}.
\end{equation}
For that, consider $\dpt{\exp_H}{\lH}{H}$ and $\dpt{\exp_G}{\lG}{G}$; from unicity of the exponential, for any $X\in\lH$, $\exp_HX=\exp_GX$, so that one can simply write ``$\exp$''\ instead of ``$\exp_h$''\ or ``$\exp_G$''.

Now, if $X\in\lH$, the map $t\to\exp tX$ is a curve in $H$. But it is not immediately clear that such a curve in $H$ is automatically build from a vector in $\lH$ rather than in $\lG$.  More precisely, consider a $X\in\lG$ such that $t\to\exp tX$ is a path (continuous curve) in H. By lemma~\ref{lem:var_cont_diff}, the map $t\to\exp tX$ is differentiable and thus by derivation, $X\in\lH$.
The characterisation \eqref{eq:path_alg} is proved.

Thus $\lH$ is a Lie subalgebra of $\lG$.

\subdem{Second item}
For the second part, we consider $\lH$ any subalgebra of $\lG$ and $H$, the smallest subgroup of $G$ which contains $\exp\lH$. We also consider a basis $\{X_1,\ldots,X_n\}$ of $\lG$ such that $\{X_{r+1},\ldots,X_n\}$ is a basis of $\lH$.

By corollary~\ref{cor:/24}, the set of linear combinations of elements of the form $X(M)$ with $M=(0,\ldots,0,m_{r+1},\ldots,m_r)$ form a subalgebra of $U(\lG)$. If $X=x_1X_1+\cdots+x_nX_n$, we define $|X|=(x_1^2+\cdots+x_n^2)^{1/2}$ ($x_i\in\eR$).

Let us consider a $\delta>0$ such that $\exp$ is a diffeomorphism (normal neighbourhood) from $B_{\delta}=\{X\in\lG:|X|<\delta\}$ to a neighbourhood $N_e$ of $e\in G$ and such that $\forall x,y,xy\in N_e$,
\begin{equation}\label{eq:coord_xy}
   (xy)_k=\sum_{M,N}C^{[k]}_{MN}x^My^N
\end{equation}
holds\footnote{The validity of this second condition is assured during the proof of theorem~\ref{tho:loc_isom} which is not given here.}. We note $V=\exp(\lH\cap B_{\delta})\subset N_e$. The map
\[
   \exp(x_{r+1}X_{r+1}+\cdots+x_nX_n)\to(x_{r+1},\ldots,x_n)
\]
is a coordinate system on $V$ for which $V$ is a connected manifold. But $\lH\cap B_{\delta}$ is a submanifold of $B_{\delta}$, then $V$ is a submanifold of $N_e$ and consequently of~$G$.

Let $x$, $y\in V$ such that $xy\in N_e$ (this exist: $x=y=e$); the canonical coordinates of $xy$ are given by \eqref{eq:coord_xy}. Since $x_k=y_k=0$ for $1\leq k\leq r$, $(xy)_k=0$ for the same $k$ because for $(xy)_k$ to be non zero, one need $m_1=\ldots=m_r=n_1=\ldots=n_r=0$ -- otherwise, $x^M$ or $y^N$ is zero. Now we looks at $C^{[k]}_{MN}$ for such a $k$ (say $k=1$ to fix ideas): $[k]=(\delta_{11},\ldots,\delta_{1k})=(1,0,\ldots,0)$ and by definition of the $C$'s,
\[
   X(M)X(N)=\sum_PC_{MN}^PX(P).
\]
But we had seen that the set of the $X(A)$ with $A=(0,\ldots,0,a_{r+1},\ldots,a_n)$ form a subalgebra of $U(\lG)$. Then, only terms with $P=(0,\ldots,0,p_{r+1},\ldots,p_n)$ are present in the sum; in particular, $C_{MN}^{[k]}=0$ for $k=1,\ldots,r$. Thus $VV\cap N_e\subset V$.

The next step is to consider $\mV$, the set of all the subset of $H$ whose contains a neighbourhood of $e$ in $V$. We can check that this fulfils the six axioms of a topological group\index{topological!group}:

\begin{enumerate}
\item The intersection of two elements of $\mV$ is in $\mV$;
\item the intersection of all the elements of $\mV$ is $\{e\}$;
\item any subset of $H$ which contains a set of $\mV$ is in $\mV$;
\item If $\mU\in\mV$, there exists a $\mU_1\in\mV$ such that $\mU_1\mU_1\subset\mU$ because $VV\cap N_e\subset V$;
\item if $\mU\in\mV$, then $\mU^{-1}\in\mV$ because the inverse map is differentiable and transforms a neighbourhood of $e$ into a neighbourhood of $e$;
\item if $\mU\in\mV$ and $h\in H$, then $h\mU h^{-1}\in\mV$.
\end{enumerate}

To see this last item, we denote by $\log$ the inverse map of $\dpt{\exp}{B_{\delta}}{N_e}$. By definition of $V$, it sends $V$ on $\lH\cap B_{\delta}$. If $X\in\lG$, there exists one and only one $X'\in\lG$ such that $he^{tX}h^{-1}=e^{tX'}$ for any $t\in\eR$. Indeed we know that $he^{X}h^{-1}=e^{\Ad_hX}$, then $X'$ must satisfy $e^{tX'}=e^{\Ad_htX}$. If it is true for any $t$, then, by derivation, $X'=\Ad_hX$.

The map $X\to X'$ is an automorphism of $\lG$ which sent $\lH$ on itself. So one can find a $\delta_1$ with $0<\delta_1<\delta$ such that
\[
   h\exp({B_{\delta_1}\cap\lH})h^{-1}\subset V.
\]
Indeed, $he^{\lH} h^{-1}\subset\lH$, so that taking $\delta_1<\delta$, we get the strict inclusion. We can choose $\delta_1$ even smaller to satisfy $he^{B_{\delta_1}}h^{-1}\subset N_e$. Since the map $X\to\log(he^{X}h^{-1})$ from $B_{\delta_1\cap\lH}$ to $B_{\delta}\cap\lH$ is regular, the image of $B_{\delta_1}\cap\lH$ is a neighbourhood of $0$ in $\lH$. Thus $he^{B_{\delta_1}\cap\lH}h^{-1}$ is a neighbourhood of $e$ in $V$. Finally, $h\mU h^{-1}\in\mV$ and the last axiom of a topological group is checked.

This is important because there exists a topology on $H$ such that $H$ becomes a topological group and $\mV$ is a family of neighbourhood of $e$ in $H$. In particular, $V$ is a neighbourhood of $e$ in $H$.

For any $z\in G$, we define the map $\dpt{\phi_z}{zN_e}{B_{\delta}}$ by
\begin{equation}
  \phi_z(ze^{x_1X_1+\cdots+x_nX_n})=(x_1,\ldots,x_n),
\end{equation}
and we denote by $\varphi_z$ the restriction of $\phi_z$ to $zV$. If $z\in H$, then $\varphi_z$ sends the neighbourhood $zV$ of $z$ in $H$ to the open set $B_{\delta}\cap\lH$ in $\eR^{n-r}$. Indeed, an element of $zV$ is a $ze^Z$ with $Z\in\lH\cap B_{\delta}$ which is sent by $\varphi_z$ to an element of $\lH\cap B_{\delta}$. (we just have to identify $x_1X_1+\cdots+x_nX_n$ with $(x_1,\ldots,x_n)$).

Moreover, if $z_1,z_2\in H$, the map $\varphi_{z_1}\circ\varphi_{z_2}^{-1}$ is the restriction to an open subset of $\lH$ of $\phi_{z_1}\circ\phi_{z_2}$. Then $\varphi_{z_1}\circ\varphi_{z_2}^{-1}$ is differentiable. Conclusion: $(H,\varphi_z: z\in H)$ is a differentiable manifold.

Recall that the definition of $\lH$ was to be a subalgebra of $\lG$; therefore $V=e^{\lH\cap B_{\delta}}$ is a submanifold of $G$. But the left translations are diffeomorphism of $H$ and $H$ is the smallest subgroup of $G$ containing $e^{\lH}$. Thus $H$ is a manifold on which the multiplication is diffeomorphic and consequently, $H$ is a Lie subgroup of $G$.

Rest to prove that the Lie algebra of $H$ is $\lH$ and the unicity part of the theorem.

We know that $\dim H=\dim\lH$ and moreover for $i>r$, the map $t\to\exp tX_i$ is a curve in $H$. Now, the fact that $\lH$ is the set of $X\in\lG$ such that $t\to\exp tX$ is a path in $H$ show that $X_i\in\lH$. Then the Lie algebra of $H$ is $\lH$ and $H$ is a connected group because it is generated by $\exp\lH$ which is a connected neighbourhood of $e$ in $H$.

We turn our attention to the unicity part. Let $H_1$ be a connected Lie subgroup of $G$ such that $T_eH_1=\lH$. Since $\exp_{\lH}X=\exp_{\lH_1}X$, $H=H_1$ as set. But $\exp$ is a differentiable diffeomorphism from a neighbourhood of $0$ in $\lH$ to a neighbourhood of $e$ in $H$ and $H_1$, so as Lie groups, $H$ and $H_1$ are the same.

Let us consider an element $X\in\lG$ such that $\exp tX\in H$ for every $t\in\eR$, and the map $\dpt{\varphi}{\eR}{G}$, $\varphi(t)=\exp tX$. This is continuous, then there exists a connected neighbourhood $\mU$ of $0$ in $\eR$ such that $\varphi(\mU)\subset V$. Then $\varphi(\mU)\subset H\cap V$ and the connectedness of $\varphi(\mU)$ makes $\varphi(\mU)\subset\exp\mU_h$. But $\exp\mU_h$ is an arbitrary small neighbourhood of $e$ in $H$; the conclusion is that $\varphi$ is a continuous map from $\eR$ into $H$. Indeed, we had chosen $X$ such that $\exp tX\in H$.

Moreover, we know that
\[
  e^{(t_0+\epsilon)X}=e^{t_0X}e^{\epsilon X},
\]
but $\exp \epsilon X$ can be as close to $e$ as we want (this proves the continuity at $t_0$). Then $\varphi$ is a path in $H$.

In definitive, we had shown that $\exp tX\in H$ implies that $t\to\exp tX$ is a path. Now equation \eqref{eq:path_alg} gives the result.

\end{proof}

\begin{corollary}
Let $G$ be a Lie group and $H_1$, $H_2$, two subgroups both having a finite number of connected components (each for his own topology). If $H_1=H_2$ as sets, then $H_1=H_2$ as Lie groups.
\end{corollary}

\begin{proof}
The proposition shows that $H_1$ and $H_2$ have same Lie algebra. But any Lie subalgebra of $\lG$ is the Lie algebra of exactly one connected subgroup of $G$ (theorem~\ref{tho:gp_alg}). Then as Lie groups, ${H_1}_0={H_2}_0$. Since $H_1$ and $H_2$ are topological groups, the equality of they topology on one connected component gives the equality everywhere (because translations are differentiable).
\end{proof}

\begin{lemma}
Let $\lG$ admit a direct sum decomposition (as vector space) $\lG=\lM\oplus\lN$. Then there exists open and bounded neighbourhoods $\mU_m$ and $\mU_n$ of $0$ in $\lM$ and $\lN$ such that the map
		\begin{equation}
		\begin{aligned}
			\phi \colon \mU_m\times\mU_n &\to G\
			(A,B)&\mapsto e^Ae^B
		\end{aligned}
	\end{equation}
is a diffeomorphism between $\mU_m\times\mU_n$ and an open neighbourhood of $e$ in $G$.
 \label{lem:decomp}
\end{lemma}


\begin{proof}
Let $\{X_1,\ldots,X_n\}$ be a basis of $\lG$ such that $X_i\in\lM$ for $1\leq i\leq r$ and $X_j\in\lN$ for $r<j\leq n$. We consider $\{t_1,\ldots,t_n\}$, the canonical coordinates of $\exp(x_1X_1+\cdots+x_rX_r)\exp(x_{r+1}X_{r+1}+\cdots+x_nX_n)$ in this coordinate system. By properties of the exponential, the function $\varphi_j$ defined by $t_j=\varphi_j(x_1,\ldots,x_n)$ is differentiable at $(0,\ldots,0)$. If $x_i=\delta_{ij}s$, then $t_i=\delta_{ij}s$ and the Jacobian of
\[
   \dsd{(\varphi_1,\ldots,\varphi_n)}{(x_1,\ldots,x_n)}
\]
is $1$ for $x_1=\ldots=x_n=0$. Thus $d\varphi_e$ is a diffeomorphism and so $\varphi$ is a locally diffeomorphic.
\end{proof}

\begin{theorem}
Let $G$ be a Lie group whose Lie algebra is $\lG$ and $H$, a closed subgroup (not specially a \emph{Lie} subgroup) of $G$. Then there exists one and only one analytic structure on $H$ for which $H$ is a topological Lie subgroup of $G$.
\label{tho:diff_sur_ferme}
\end{theorem}

\begin{remark}
A \textit{topological} Lie subgroup\index{topological!Lie subgroup} is stronger that a common Lie subgroup because it needs to be a topological subgroup: it must carry \emph{exactly} the induced topology. In our definition of a Lie group, this feature doesn't appears.
\end{remark}

\begin{proof}
   Let $\lH$ be the subspace of $\lG$ defined by
\begin{equation}\label{eq:lH_de_G}
  \lH=\{X\in\lG\tq \forall t\in\eR,\, e^{tX}\in H\}.
\end{equation}
We begin to show that $\lH$ is a subalgebra of $\lG$; i.e. to show that $t(X+Y)\in\lH$ and $t^2[X,Y]\in\lH$ if $X$, $Y\in\lH$. Remark that $X\in\lH$ and $s\in\eR$ implies $sX\in\lH$. Consider now $X$, $Y\in\lH$ and the classical formula:
\begin{subequations}
\begin{align}
\left(  \exp(\frac{t}{n}X)\exp(\frac{t}{n}Y)  \right )^n
                       =\exp( t(X+Y)+\frac{t^2}{2n}[X,Y]+o(\frac{1}{n^2}) ),\\
\left(  \exp(-\frac{t}{n}X)\exp(-\frac{t}{n}Y)\exp(\frac{t}{n}X)\exp(\frac{t}{n}Y)   \right)^{n^2}
                       =\exp\left( t^2[X,Y]+o(\frac{1}{n})\right).
\end{align}
\end{subequations}
The left hand side of these equations are in $H$ for any $n$; but, since $H$ is closed, it keeps in $H$ when $n\to\infty$. The right hand side, at the limit, is just $\exp(t(X+Y))$ and $\exp(t^2[X,Y])$, which keeps in $H$ for any $t$. Thus $X+Y$ and $[X,Y]$ belong to $\lH$. The space $\lH$ is thus a Lie subalgebra of $\lG$.

Let $H^*$ be the connected Lie subgroup of $G$ whose Lie algebra is $\lH$ (existence and unicity from~\ref{tho:gp_alg}). From the proof of theorem~\ref{tho:gp_alg}, we know that $H^*$ is the smallest subgroup of $G$ containing $\exp\lH$, then it is made up from products and inverses of elements of the type $e^X$ with $X\in\lH$, and thus is is included in $H$ by definition of $\lH$. So, $H^*\subset H$.

We will show that if we put on $H^*$ the induced topology from $G$ and if $H_0$ denotes the identity component of $H$, then $H^*=H_0$ as topological groups. For this, we first have to show the equality as set and then prove that if $N$ is a neighbourhood of $e$ in $H^*$, then it is a neighbourhood of $e$ in $H_0$. In facts, the equality as set can be derives from this second fact. Indeed, since $H_0$ is a connected topological group, it is generated by any neighbourhood of $e$, so if one can show that any neighbourhood $N$ of $e$ in $H^*$ is a neighbourhood of $e$ in $H$, then $H^*$ is a neighbourhood of $e$ in $H_0$ and then $H_0$ should be generated by $H^*$, so that $H_0\subset H^*$ (as set). Moreover, the most general element of $H^*$ is product and inverse of $e^X$ with $X\in\lH$ and $e^X$ is connected to $e$ by the path $e^{tX}$ ($\dpt{t}{1}{0}$). Then $H^*\subset H_0$, and $H^*=H_0$ as set. Immediately, $H^*=H_0$ as topological groups from our assertion about neighbourhoods of $e$. Let us now prove it.

We consider a neighbourhood $N$ of $e$ in $H^*$ and suppose that this is not a neighbourhood of $e$ in $H$. Thus there exists a sequence $c_k\in H\setminus N$ such that $c_k\to e$ in the sense of the topology on $G$. Indeed, a neighbourhood of $e$ in the sense of $H$ must contains at least a point which is not in $N$ because if we have an open set of $H$ around $e$ included in $N$, then $N$ is a neighbourhood of $e$ for $H$. So we consider a suitable sequence of such open sets around $e$ and one element not in $N$ in each of them. There is the $c_k$'s\quext{Je crois qu'on utilise l'axiome du choix.}.

Using lemma~\ref{lem:decomp} with a decomposition $\lG=\lH\oplus\lM$ (i.e. $\lM$: a complementary for $\lH$ for $\lG$), one can find sequences $A_k\in\mU_m$ and $B_k\in\mU_n$ such that
\[
   c_k=e^{A_k}e^{B_k}.
\]
Here, $\mU_m$ is an open neighbourhood of $0$ in $\lM$ and $\mU_h$, an open neighbourhood of $0$ in $\lH$.

As $e^{B_k}\in N$ and $c_k\in H\setminus N$, $A_k\neq 0$ and $\lim A_k=\lim B_k=0$ (because $(A,B)\to e^Ae^B$ is a diffeomorphism and $e^0e^0=e$ -- and also because all is continuous and thus has a good behaviour with respect to the limit). The set $\mU_m$ is open and bounded --this is a part of the lemma. Then there exist a sequence of positive reals numbers $r_k\in$ such that $r_kA_k\in\mU_m$ and $(r_k+1)A_k\notin\mU_m$. We know that $\mU_m$ is a bounded open subset of the vector space $\lM$, then the whole sequences $r_kA_k$ and $(r_k+1)A_k$ are in a compact domain of $\lM$. Then --by eventually considering subsequences-- there are no problems to consider limits of these sequences in $\lM$: $r_kA_k\to A\in\lM$ (not necessary in $\mU_m$). Since $A_k\to 0$, the point $A$ is the common limit of $r_kA_k\in\mU_m$ and of $(r_k+1)A_k\notin\mU_m$. Thus $A$ is in the boundary of $\mU_m$; in particular, $A\neq 0$.

On the other hand, consider two integers $p,q$ with $q>0$. One can find sequences $s_k,t_k\in\eN$ and $0\leq t_k<q$ such that $pr_k=qs_k+t_k$. It is clear that
\begin{equation}
  \lim_{k\to\infty}\frac{t_k}{q}A_k=0,
\end{equation}
thus
\[
   \exp \frac{p}{q}A=\lim \exp\frac{pr_k}{a}A_k=\lim (\exp A_k)^{s_k},
\]
which belongs to $H$. By continuity, $\exp tA\in H$ for any $t\in\eR$ and finally $A\in\lH$; this contradict $A\neq 0$ so that $A\in\lM$ (because by definition, $A\in\lM$ and the sum $\lG=\lH\oplus\lM$ is direct).

By its definition, $H^*$ has an analytic structure of Lie subgroup of $G$; but we had just proved that the induced topology from $G$ is the one of $H_0$ which by definition is a submanifold of $G$. So the set $H_0=H^*$ becomes a submanifold of $G$ whose topology is compatible with the analytic structure: thus it is a Lie subgroup of $G$. From analyticity, this structure is extended to the whole $H$.

\begin{probleme}
Est-ce bien vrai, tout \c ca ? En particulier, je n'utilise pas que $H_0$ est ouvert dans $H$ (ce qui est un tho de topo classique : je ne vois pas pourquoi Helgason fait tout un cin\'ema --que je ne comprends pas-- dessus). En prenant $N=H^*$, on a juste d\'emontr\'e que $H_0$ est un voisinage de $e$ dans $H$, mais Ã§a, on le savait bien avant.
\end{probleme}

The unicity part comes from the corollary~\ref{cor:top_subgroup}.
\end{proof}


With the notations and the structure of theorem~\ref{tho:diff_sur_ferme}, the subgroup $H$ is discrete if and only if $\lH=\{0\}$. Indeed, recall the definition \eqref{eq:lH_de_G}:
\[
  \lH=\{X\in\lG: \forall t\in\eR, e^{tX}\in H\},
\]
and the fact that there exists a neighbourhood of $e$ in $H$ on which the exponential map is a diffeomorphism.

\begin{remark}
This fact should not be placed after the following lemma. In fact, we use here just the existence of normal neighbourhood (which is a common result) while the following lemma gives much more than normal neighbourhood.
\end{remark}

The lemma (without proof):

\begin{lemma}
 Let $G$ be a Lie group and $H$, a Lie subgroup of $G$ ($\lG$ and $\lH$ are the corresponding Lie algebras). If $H$ is a topological subspace of $G$, then there exists an open neighbourhood $V$ of $0$ in $\mG$ such that
 \begin{enumerate}
 \item $\exp$ is a diffeomorphism between $V$ and an open neighbourhood of $e$ in~$G$,
 \item $\exp(V\cap\lH)=(\exp V)\cap H$.
 \end{enumerate}
\label{lem:sugroup_normal}
\end{lemma}

\begin{definition}
A \defe{differentiable subgroup}{differentiable!subgroup} is a connected Lie subgroup.
\end{definition}

\begin{corollary}
Let $G$ be a Lie group, and $K$, $H$ two differentiable subgroups of $G$. We suppose $K\subset H$. Then $K$ is a differentiable subgroup of the Lie group $H$.
\end{corollary}

\begin{proof}
The Lie algebras of $K$ and $H$ are respectively denoted by $\lK$ and $\lH$. We denote by $K^*$ the differentiable subgroup of $H$ which has $\lK$ as Lie algebra. The differentiable subgroups $K$ and $K^*$ have same Lie algebra, and then coincide as Lie groups.
\end{proof}

\label{pg:ex_topo_Lie}
Consider the group $T=S^1\times S^1$ and the continuous map $\dpt{\gamma}{\eR}{T}$ given by
\[
  \gamma(t)=(e^{it},e^{i\alpha t})
\]
with a certain irrational $\alpha$ in such a manner that $\gamma$ is injective and $\Gamma=\gamma(\eR)$ is dense in $T$.

The subset $\Gamma$ is not closed because his complementary in $T$ is not open: any neighbourhood of element $p\in T$ which don't lie in $\Gamma$ contains some elements of $\Gamma$. We will show that the inclusion map $\dpt{\iota}{\Gamma}{T}$ is continuous. An open subset of $T$ is somethings like
\[
  \mO=(e^{iU},e^{iV})
\]
where $U,V$ are open subsets of $\eR$. It is clear that
\[
   \iota^{-1}(\mO)=\{ \gamma(t)\tq t\in U+2k\pi,\alpha t\in V+2m\pi \},
\]
but the set of elements $t$ of $\eR$ which satisfies it is clearly open. Then $\Gamma$ has at least the induced topology from $T$ (as shown in proposition~\ref{prop:topo_sub_manif}). In fact, the own topology of $\Gamma$ is \emph{more} than the induced: the open subsets of $\Gamma$ whose are just some small segments clearly doesn't appear in the induced topology. Thus the present case is an example (and not a counter-example) of theorem~\ref{tho:H_ferme}.

This example show the importance of the condition for a topological subspace to have \emph{exactly} the induced topology. If not, any Lie subgroup were a topological Lie subgroup because a submanifold has at least the induced topology. We will go further with this example after the proof.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Matrix Lie group and its algebra}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooTSAJooNtjgMD}

In this section we deal with Lie groups made from matrices, that is subgroups of \( \GL(n, \eC)\) (typically \( \SO(n)\) or \( \SU(n)\)) and their Lie algebra. We will denote the identity either by \( e\) or by \( \mtu\).

\begin{normaltext}      \label{NORMooHZGKooJEiamo}
    It is time to reread the remark \ref{REMooJQFHooQuoZxt}. In this section, when \( \gamma\) is a path in the matrix group \( G\), we denote by \( \gamma'(0)\) the ``usual'' derivative of \( \gamma\): that is the component-wise derivative; not the differential operator.

    We denote by \( D_{\gamma}\) the differential operator
    \begin{equation}
        \begin{aligned}
            D_{\gamma}\colon  C^{\infty}(G)&\to \eR \\
            f&\mapsto \Dsdd{ f\big( \gamma(t) \big) }{t}{0}. 
        \end{aligned}
    \end{equation}

    We aim to study the link between \( D_{\gamma}\) and \( \gamma'(0)\).

    From the Lie group of matrix \( G\) we can build (at least) two Lie algebras\footnote{Definition \ref{DEFooVBPKooGxlDBn}.}:
    \begin{itemize}
        \item The usual Lie algebra of the group: \( T_eG\) with the definition \ref{DEFooKDCPooZOJsMD}. As set, this is
            \begin{equation}
                T_eG=\{ D_{\gamma}\st \gamma(0)=e \}
            \end{equation}
            with the implicit that \( \gamma\) is a smooth path in \( G\).
        \item 
            The set of ``usual'' derivatives of the paths in \( G\):
            \begin{equation}
                G'=\{ \gamma'(0)\tq \gamma(0)=e \}.
            \end{equation}
            This is a set of matrices on which we can use the bracket \( [X,Y]=XY-YX\) (matrix product). We will see the following facts.
            \begin{itemize}
                \item 
                    The set \( G'\) is a Lie algebra in proposition \ref{PROPooUKITooLnEKZW},
                \item
                    The Lie algebras \( G'\) and \( T_eG\) are isomorphic as Lie algebras in theorem \ref{THOooWQGMooHyjRtx} for the case \( G=\GL(n,\eC)\)
                \item
                    When \( H\) is a Lie subgroup of \( \GL(n,\eC)\), the Lie algebras \( H'\) and \( T_eH\) are isomorphic as Lie algebras in proposition \ref{PROPooSQHLooGQAykc} for the Lie subgroups of \( \GL(n,\eC)\).
            \end{itemize}
    \end{itemize}
\end{normaltext}

\begin{lemma}[\cite{MonCerveau}]
    Let \( G\) be a matrix Lie group, et \( g\in G\) and \( X\in G'\). Then \( gXg^{-1}\in G'\).
\end{lemma}

\begin{proof}
    Let \( x\colon \eR\to G\) be a smooth path such that \( X=x'(0)\). Then we the derivative of the path given by the matrix product
    \begin{equation}
        t\mapsto gx(t)g^{-1}
    \end{equation}
    is \( gXg^{-1}\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooHQUYooSoiKbI}
    Let \( G\) be a matrix Lie group. Then \( G'\) is a vector space on \( \eR\).
\end{lemma}

\begin{proof}
    Let \( X,Y\in G'\) be the derivatives of the paths \( x\) and \( y\). If we set \( \varphi_1(t)=x(t)y(t)\) we have
    \begin{equation}
        \varphi_1'(0)=x'(0)y(0)+x(0)y'(0).
    \end{equation}
    Since \( x(0)=y(0)=e\) we have \( \varphi'(0)=X+Y\), so that \( X+Y\in G'\).

    For the product by a scalar, let the path \( \varphi_2(t)=x(\lambda t)\). The component-wise derivative
    \begin{equation}
        \varphi_2'(0)=\lambda x'(0)=\lambda X,
    \end{equation}
    so that \( \lambda X\in G'\).
\end{proof}

\begin{proposition}     \label{PROPooUKITooLnEKZW}
    Let \( G\) be a matrix Lie group. The vector space \( G'\) is a Lie algebra for the matrix commutator.
\end{proposition}

\begin{proof}
    We already know that \( G'\) is a real vector space by lemma \ref{LEMooHQUYooSoiKbI}. The fact that \( (X,Y)\mapsto XY-YX\) satisfies the axioms of a Lie algebra is easy to check. The only point is to show that if \( X,Y\in G'\), then \( [X,Y]=XY-YX\in G'\).

    Let
    \begin{equation}        \label{EQooJDTLooGWsDiq}
        \varphi(t)=x(t)Yx(-t).
    \end{equation}
    This is for sure a path in the full matrix vector space, and this is derivable because \( x\) is derivable while the matrix product is linear. So the derivative \( \varphi'(0)\) is still a matrix. The question is: why \( \varphi'(0)\in G'\) ?

    By lemma \ref{LEMooHQUYooSoiKbI}, for each \( t\) we have
    \begin{equation}
        \frac{ \varphi(t)-\varphi(0) }{ t }\in G'.
    \end{equation}
    Now, \( G'\) is a vector subspace of \( \eM(n,\eC)\) which is finite dimensional; is is thus closed and the limit belongs to \( G'\).

    Is is now a simple computation to show that \( \varphi'(0)=[X,Y]\).
\end{proof}

\begin{normaltext}
The following theorem is a Giulietta's masterpiece in the following sense:
\begin{itemize}
    \item It is fundamental because the Lie algebra isomorphism between \( T_eGL(n,\eR)\) and the matrices is used everywhere one says Â«The Lie algebra of $\SO(3)$ is the set of skew-symmetric traceless matricesÂ».
    \item
        Either I'm idiot, either I never seen that theorem even stated (let alone being proved)\footnote{There is in fact a third possibility:  this theorem is a classic one but cannot be found \emph{on internet}.}.
    \item
        I think that the fundamental misunderstanding\footnote{Once again, either I'm idiot either everybody is wrong but me\ldots well \ldots} is that in the context of Lie groups, people \emph{define} \( [X,Y]\) as being \( \ad(X)Y\) while \( \ad\) is defined as the ``second differential'' of \( \AD(g)h=ghg^{-1}\). In that case, obviously we get \( [X,Y]=XY-YX\) with the matrix product. This way fails to make the link with the commutator of vector fields as defined by \ref{DEFooHOTOooRaPwyo}.
    \item
        So you must read this proof with much care and write me if you see any mistake or unclear point.
\end{itemize}
\end{normaltext}
So here it is with the notations explained in \ref{NORMooHZGKooJEiamo}.
    

\begin{theorem}     \label{THOooWQGMooHyjRtx}
    Let \( G=\GL(n,\eC)\) be the group of invertible matrices. The map
    \begin{equation}
        \begin{aligned}
            \phi\colon G'&\to T_eG \\
            \gamma'(0)&\mapsto D_{\gamma} 
        \end{aligned}
    \end{equation}
    is 
    \begin{enumerate}
        \item
            well defined,
        \item
            bijective,
        \item
            linear,
        \item
            a Lie algebra isomorphism.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Several points to be proved.
    \begin{subproof}
        \item[\( \phi\) is well defined]
            Let \( \alpha\) and \( \beta\) be paths in \( G\) such that \( \alpha'(0)=\beta'(0)\) and let \( f\colon G\to \eR\) be a smooth function. We have to prove that \( D_{\alpha}(f)=D_{\beta}(f)\).

            We consider a chart \( \varphi\colon \mU\to \mO\) where \( \mU\) is a neighbourhood of \( 0\) in \( \eR^m\) and \( \mO\) is a neighbourhood of \( e\) in \( \GL(n,\eC)\). We suppose that \( \varphi(0)=e\). We set \( \tilde f=f\circ \varphi\), \( \tilde \alpha=\varphi^{-1}\circ \alpha\) and \( \tilde \beta=\varphi^{-1}\circ\beta\). We have
            \begin{subequations}
                \begin{align}
                    D_{\alpha}(f)&=\Dsdd{ f\big( \alpha(t) \big) }{t}{0}\\
                    &=\Dsdd{ \tilde f\big( \tilde \alpha(t) \big) }{t}{0}\\
                    &=\sum_{i=1}^m\frac{ \partial \tilde f }{ \partial x_i }\big( \tilde \alpha(0) \big)\tilde \alpha_i(0).
                \end{align}
            \end{subequations}
            Since \( \tilde \alpha(0)=\tilde \beta(0)\) we still have to prove that \( \tilde \alpha_i'(0)=\tilde \beta_i'(0)\). As you remember, \( \tilde \alpha\) is a map from \( \eR\) to \( \eR^m\), so that the following derivative is quite usual:
            \begin{subequations}
                \begin{align}
                    \tilde \alpha'(0)&=\Dsdd{ (\varphi^{-1}\circ \alpha)(t) }{t}{0}\\
                    &=d\varphi^{-1}_{\alpha(0)}\big( \alpha'(0) \big)\\
                    &=d\varphi^{-1}_{\beta(0)}\big( \beta'(0) \big).
                \end{align}
            \end{subequations}
            Thus the map \( \phi\) is well defined.
        \item[\( \phi\) is linear]
            This is from the linearity of the derivation.
        \item[\( \phi\) is injective]
            If \( \phi(\alpha')=\phi(\beta')\), then \( D_{\alpha}(f)=D_{\beta}(f)\) for every function \( f\). In that case,
            \begin{equation}
                \sum_{i=1}^m\frac{ \partial \tilde f }{ \partial x_i }(e)\tilde \alpha_i'(0)=\sum_{i=1}^m\frac{ \partial \tilde f }{ \partial x_i }(e)\tilde \beta_i'(0).
            \end{equation}
            That equation must be satisfied for every function. Taking the projection on the components, we get \( \tilde \alpha_i'(0)=\tilde b_i'(0)\), which means \( \alpha'(0)=\beta'(0)\) because \( \varphi^{-1}\) is bijective.
        \item[\( \phi\) is surjective]
            Every element of \( T_eG\) is of the form \( D_{\alpha}\) for some path \( \alpha\), so \( \phi\) is surjective.
        \item[\( \phi\) is a Lie algebra isomorphism]
            Let \( X,Y\in G'\) being the derivative of the paths \( \alpha\) and \( \beta\). We have to prove that
            \begin{equation}
                [\phi(X),\phi(Y)]=\phi[X,Y].
            \end{equation}
            If \( t\) is small enough, the paths
            \begin{subequations}
                \begin{align}
                    \alpha(t)=\mtu+tX\\
                    \beta(t)=\mtu+tY\\
                \end{align}
            \end{subequations}
            are good ones because \( \det(\mtu)\neq 0\), so that the determinant of \( \mtu+tX\) remains different from zero when \( t\) is small, whatever \( X\) is. So \( \alpha\) and \( \beta\) are paths in \( \GL(n,\eC)\). Using the general definition in differential geometry,
            \begin{subequations}        \label{SUBEQSooCYRDooFOdLrn}
                \begin{align}
                    [\phi(X),\phi(Y)]f&=[\phi(X)^L,\phi(Y)^L]_ef\\
                    &=\phi(X)^L_e\big( \phi(Y)^L(f) \big)-\phi(Y)^L_e\big( \phi(X)^L(f) \big) \label{SUBEQooOPUAooZYsZlX}.
                \end{align}
            \end{subequations}
            We focus on the first term:
            \begin{subequations}        \label{SUBEQooTUNFooFkDmuP}
                \begin{align}
                    \phi(X)^L\big( \phi(Y)^L(f) \big)&=\Dsdd{ \phi(Y)^L_{\phi(X)^L_e(t)}(f) }{t}{0}\\
                    &=\DDsdd{ f\big( (\mtu+tX)(\mtu+sY) \big) }{t}{0}{s}{0}\\
                    &=\DDsdd{ f(\mtu+tX+sY+tsXY) }{t}{0}{s}{0}\\
                    &=\Dsdd{ df_{\mtu+tX}\big( (\mtu+tX)Y \big) }{t}{0} \label{SUBEQooLHPBooTnXiZd}\\
                    &=\Dsdd{ df_{\mtu+tX}(Y) }{t}{0}+\Dsdd{ df_{\mtu+tX}(tXY) }{t}{0}   \label{SUBEQooMXJJooBFTLsM}
                \end{align}
            \end{subequations}
            where we have used the linearity of \( df_{\mtu+tX}\) and where \( XY\) stands for the matrix product. In the expression \eqref{SUBEQooLHPBooTnXiZd}, the symbol \( df\) stands for the differential of \( f\) as function from \( \eM(n,\eC)\) (as vector space), not for the differential of \( f\) on \( G\) as manifold. This is why we are allowed to put an expression as the matrix \( Y\) as argument of \( df_{\mtu+tX}\) while \( Y\) is not an element of \( T_{\mtu+tX}G\).

            The expression \eqref{SUBEQooMXJJooBFTLsM} is still made of two terms. The second one is
            \begin{equation}
                \Dsdd{ df_{\mtu+tX}(tXY) }{t}{0}=\Dsdd{ tdf_{\mtu+tX}(XY) }{t}{0}=df_{\mtu}(XY)
            \end{equation}
            where we used the Leibnitz rule\footnote{In general, notice that \( \Dsdd{ tf(t) }{t}{0}=f(0)\)}.

            The first term in \eqref{SUBEQooMXJJooBFTLsM} is computed as
            \begin{equation}
                    \Dsdd{ df_{\mtu+tX}(Y) }{t}{0}=\DDsdd{ f(\mtu+tX+sY) }{t}{0}{s}{0}.
            \end{equation}
            We set 
            \begin{equation}
                \begin{aligned}
                    \gamma\colon \eR^2&\to G \\
                    (t,s)&\mapsto \mtu+tX+sY, 
                \end{aligned}
            \end{equation}
            so that
            \begin{subequations}
                \begin{align}
                    \Dsdd{ df_{\mtu+tX}(Y) }{t}{0}&=\DDsdd{ f(\mtu+tX+sY) }{t}{0}{s}{0}\\
                    &=\DDsdd{ (\tilde f\circ\varphi^{-1}\circ\gamma)(t,s) }{t}{0}{s}{0}\\
                    &=\DDsdd{ g(t,s) }{t}{0}{s}{0}
                \end{align}
            \end{subequations}
            where the function \( g=\tilde f\circ\varphi^{-1}\circ \gamma\) is a smooth function from \( \eR^2\) to \( \eR\).        

            The expression \eqref{SUBEQooTUNFooFkDmuP} is now
            \begin{equation}
                \phi(X)^L\big( \phi(Y)^L(f) \big)=\DDsdd{ g(t,s) }{t}{0}{s}{0}+df_{\mtu}(XY).
            \end{equation}
            The commutator we have to compute, with the same computations is
            \begin{equation}
                [\phi(X),\phi(Y)]f=\DDsdd{ g(t,s) }{t}{0}{s}{0}+df_{\mtu}(XY)-\DDsdd{ g(s,t) }{t}{0}{s}{0}-df_{\mtu}(YX).
            \end{equation}
            The function \( g\) being \(  C^{\infty}\), the derivative commute and the corresponding termes annihilate each other and we are left with
            \begin{equation}
                [\phi(X),\phi(Y)]f=df_{\mtu}(XY)-df_{\mtu}(YX)=df_{\mtu}(XY-YX)
            \end{equation}
            where we used the linearity of the differential.

            In the other sense,
            \begin{equation}
                \phi[X,Y]f=\Dsdd{ f(\mtu+tXY-tYX) }{t}{0}=df_{\mtu}\big( [X,Y] \big)
            \end{equation}
            where, once again, \( df\) stands for the ``usual'' differential.
    \end{subproof}
\end{proof}

Ok. This is proved for \( G=\GL(n,\eC)\), the full matrix group. What about subgroups ? Here is the result.

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooSQHLooGQAykc}
    Let \( H\) be a Lie subgroup\footnote{Thanks to the Cartan theorem \ref{THOooDEJHooVKJYBL}, there are plenty of them.} of \( \GL(n,\eC)\). With the same notations as above, the map
    \begin{equation}
        \begin{aligned}
            \phi\colon H'&\to T_eH \\
            \gamma'(0)&\mapsto D_{\gamma} 
        \end{aligned}
    \end{equation}
    is a Lie algebra isomorphism.
\end{proposition}

\begin{proof}
    We have to prove that
    \begin{equation}        \label{EQooRLBBooYgHhtH}
        \phi[X,Y]f=[\phi(X),\phi(Y)]f
    \end{equation}
    for every \( X,Y\in H'\) and \( f\in  C^{\infty}(H)\). For that, we will see the left and right hand sides of \eqref{EQooRLBBooYgHhtH} in \( G=\GL(n,\eC)\), and use the already proved result, theorem \ref{THOooWQGMooHyjRtx}.

    If \( X,Y\in H'\) we know from proposition \ref{PROPooUKITooLnEKZW} that \( [X,Y]\in H'\). Thus there exists a path \( \gamma\colon \eR\to H\) such that \( [X,Y]=\gamma'(0)\). We consider the extension\footnote{The proposition \ref{PROPooOTZQooIfboXV} can be used since \( H\) is a submanifold of \( G\) by \ref{PROPooFXZJooCOFXZX}.} \( \tilde f\colon W\to \eR\) of \( f\) such that \( \tilde f=f\) on \( H\) and \( W\) is an open set around \( e\) in \( \GL(n,\eC)\). For the sake of making things complicated we also define \( \tilde \gamma=\iota\circ \gamma\) where \( \iota\colon H\to \GL(n,\eC)\) is the inclusion. With all that we have
    \begin{equation}
        \phi[X,Y]f=\Dsdd{ f\big( \gamma(t) \big) }{t}{0}=\Dsdd{ \tilde f\big( \tilde \gamma(t) \big) }{t}{0}=\clubsuit.
    \end{equation}
    At this point, notice that \( [X,Y]\in \GL(n,\eC)'\) and \( [X,Y]=\tilde \gamma'(0)\), so that if we consider \( \tilde \phi\colon \GL(n,\eC)\to T_e\GL(n,\eC)\) we also have
    \begin{equation}
        \clubsuit=\Dsdd{ \tilde f\big( \tilde \gamma(t) \big) }{t}{0}=\tilde \phi[X,Y]\tilde f=\big[ \tilde \phi(X),\tilde \phi(Y) \big]\tilde f
    \end{equation}
    where we used the result \ref{THOooWQGMooHyjRtx} on \( \GL(n,\eC)\).

    We still have to prove that \( \tilde \phi(X)\tilde \phi(Y)\tilde f=\phi(X)\phi(Y)f\). Using, among others the formula \ref{SUBEQSooHKWMooQbeStl} adapted to \( \tilde \phi(X)\) instead of \( X\):
    \begin{subequations}
        \begin{align}
            \tilde \phi(X)\tilde \phi(Y)\tilde f&=\Dsdd{ \big( \tilde \phi(Y)^L\tilde f \big)\big( \alpha(t) \big) }{t}{0}\\
            &=\Dsdd{ \tilde \phi(Y)^L_{\alpha(t)}\tilde f }{t}{0}\\
            &=\DDsdd{ \tilde f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}.
        \end{align}
    \end{subequations}
    At this point, notice that \( \alpha(t)\) and \( \beta(u)\) are elements in \( H\) which is a group, so \( \tilde f\big( \alpha(t)\beta(u) \big)=f\big( \alpha(t)\beta(u) \big)\). Thus
    \begin{subequations}
        \begin{align}
            \tilde \phi(X)\tilde \phi(Y)\tilde f&=\DDsdd{ \tilde f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}\\
            &=\DDsdd{ f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}\\
            &=\phi(X)\phi(y)f.
        \end{align}
    \end{subequations}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
    Let \( G\) be a Lie group of matrices and \( X\in T_eG\) such that 
    \begin{equation}
        df_e(X)=0
    \end{equation}
    for every smooth function \( f\colon G\to \eR\). Then \( X=0\).
\end{lemma}

\begin{proof}
    We consider the functions \( \pr_{ij}\colon G\to \eR\) defined by \( \pr_{ij}(A)=A_{ij}\). If \( g\colon \eR\to G\) is a path, for every \( t\) we have \( \pr_{ij}g(t)=g(t)_{ij}\) and then
    \begin{equation}
        \Dsdd{ \pr_{ij}g(t) }{t}{0}=g'(0)_{ij}.
    \end{equation}
    Then we build
    \begin{equation}
        \begin{aligned}
            f\colon G&\to \eR \\
            A&\mapsto \pr_{11}(A)\pr_{ij}(A). 
        \end{aligned}
    \end{equation}
    If \( g\colon \eR\to G\) is a path such that \( g(0)=e\) and \( g'(0)=X\), then we have
    \begin{subequations}
        \begin{align}
            \Dsdd{ f\big( g(t) \big) }{t}{0}&=\Dsdd{ \pr_{11}\big( g(t) \big)\pr_{ij}\big( g(t) \big) }{t}{0}\\
            &=\pr_{11}g(0)\Dsdd{ \pr_{ij}g(t) }{t}{0}+\Dsdd{ \pr_{11}g(t) }{t}{0}\pr_{ij}g(0)\\
            &=X_{ij}+\delta_{ij}X_{11}\\
            &=X_{ij}+\delta_{ij}X_{11}.
        \end{align}
    \end{subequations}
    We know that this is zero for every choice of \( ij\):
    \begin{equation}
        X_{ij}+\delta_{ij}X_{11}=0
    \end{equation}
    In particular with \( i=j=1\) we have \( 2X_{11}=0\), so that \( X_{11}=0\). Then we are left with \( X_{ij}=0\) for every \( ij\).
\end{proof}

\section{Adjoint group, inner automorphisms}\label{sec:adj_gp}
%--------------------------

Let $\lA$ be a \emph{real} Lie algebra. We denote by $GL(\lA)$\nomenclature[G]{$GL(\lA)$}{The group of nonsingular endomorphisms of $\lA$} the group of all the nonsingular endomorphisms of $\lA$: the linear and nondegenerate operators on $\lA$ as vector space. An element $\sigma\in\GL(\lA)$ does not specially fulfils somethings like $\sigma[X,Y]=[\sigma X,\sigma Y]$. The Lie algebra $\gl(\lA)$\nomenclature[G]{$\protect\gl(\lA)$}{space of endomorphisms with usual bracket} is the vector space of the endomorphisms (without non degeneracy condition) endowed with the usual bracket $(\ad A)B=[A,B]=A\circ B-B\circ A$. The map $X\to\ad X$ is a homomorphism from $\lA$ to the subalgebra $\ad(\lA)$ of $\gl(\lA)$.

The group $\Int(\lA)$\nomenclature[G]{$\Int(\lA)$}{Adjoint group of $\lA$} is the analytic Lie subgroup of $\GL(\lA)$ whose Lie algebra is $\ad(\lA)$ by theorem~\ref{tho:gp_alg}. This is the \defe{adjoint group}{adjoint!group}\index{group!adjoint} of $\lA$.

\begin{proposition}
The group $\Aut(\lA)$\nomenclature[G]{$\Aut\lA$}{Group of automorphisms of $\lA$} of all the automorphisms of $\lA$ is a closed subgroup of $\GL(\lA)$.
\end{proposition}

\begin{proof}
The property which distinguish the elements in $\Aut(\lA)$ from the ``commons'' elements of $\GL(\lA)$ is the preserving of structure: $\varphi[A,B]=[\varphi A,\varphi B]$. These are equalities, and we know that a subset of a manifold which is given by some equalities is closed.
\end{proof}

Now, theorem~\ref{tho:diff_sur_ferme} provides us an unique analytic structure on $\Aut(\lA)$ in which it is a topological Lie subgroup of $\GL(\lA)$. From now we only consider this structure. We denote by $\partial(\lA)$\nomenclature[G]{$\partial\lA$}{The Lie algebra of $\Aut(\lA)$} the Lie algebra of $\Aut(\lA)$: this is the set of the endomorphisms $D$ of $\lA$ such that $\forall t\in\eR$, $e^{tD}\in\Aut(\lA)$. By differencing the equality
\begin{equation}\label{eq:exp_der}
  e^{tD}[X,Y]=[e^{tD}X,e^{tD}Y]
\end{equation}
with respect to $t$, we see\footnote{As usual, if we consider a basis of $\lA$ as vector space, the expression in the right hand side of \[[e^{tD}X,e^{tD}Y]=\ad(e^{tD}X)e^{tD}X\] can be seen as a product matrix times vector, so that Leibnitz works.} that $D$ is a \defe{derivation}{derivation!of a Lie algebra} of $\lA$:
\begin{equation}
  D[X,Y]=[DX,Y]+[X,DY]
\end{equation}
for any $X$, $Y\in\lA$. Conversely, consider $D$, any derivation of $\lA$; by induction,
\begin{equation}
   D^k[X,Y]=\sum_{i+j=k}\frac{k!}{i!j!}[D^iX,D^jY]
\end{equation}
where by convention, $D^0$ is the identity in $\lA$. This relation shows that $D$ fulfils condition \eqref{eq:exp_der}, so that any derivation of $\lA$ lies in $\partial(\lA)$. Then
\[
  \partial(\lA)=\{\text{derivations of }\lA\}.
\]
The Jacobi identities show that
\[
\ad(\lA)\subset\partial(\lA).    \label{pg:ad_subset_der}
\]
From this, we deduce\footnote{See error~\ref{err:Intt_Aut}}: 
\begin{equation}\label{eq:int_sub_aut}
  \Int(\lA)\subset\Aut(\lA).
\end{equation}
Indeed the group $\Int(\lA)$ being connected, it is generated\footnote{See proposition~\ref{PropUssGpGenere}} by any neighbourhood of $e$; note that $\Aut(\lA)$ has not specially this property. We take a neighbourhood of $e$ in $\Int(\lA)$ under the form  $\exp V$  where $V$ is a sufficiently small neighbourhood of $0$ in $\ad(\lA)$ to be a neighbourhood of $0$ in $\partial(\lA)$ on which $\exp$ is a diffeomorphism. In this case, $\exp V\subset\Aut(\lA)$ and then $\Int(\lA)\subset\Aut(\lA)$.

Elements of $\ad(\lA)$ are the \defe{inner derivations}{derivation!inner} while the ones of $\Int(\lA)$ are the \defe{inner automorphisms.}{inner!automorphism}

Let $\mO$ be an open subset of $\Aut(\lA)$; for a certain open subset $U$ of $\GL(\lA)$, $\mO=U\cap\Aut(\lA)$. Then
\begin{equation}
  \iota^{-1}(\mO)=\mO\cap\Int(\lA)
           =U\cap\Aut(\lA)\cap\Int(\lA)
       =U\cap\Int(\lA).
\end{equation}

The subset $U\cap\Int(\lA)$ is open in $\Int(\lA)$ for the topology because $\Int(\lA)$ is a Lie\quext{Is it true??} subgroup of $\GL(\lA)$ and thus has at least the induced topology. This proves that the inclusion map $\dpt{\iota}{\Int(\lA)}{\Aut(\lA)}$ is continuous.

The lemma \ref{lem:var_cont_diff} and the consequence below makes $\Int(\lA)$ a Lie subgroup of $\Aut(\lA)$. Indeed $\Int(\lA)$ and $\Aut(\lA)$ are both submanifolds of $\GL(\lA)$ which satisfy \eqref{eq:int_sub_aut}. 


By definition, $\Aut(\lA)$ has the induced topology from $\GL(\lA)$. Then $\Int(\lA)$ is a submanifold of $\Aut(\lA)$. 
This is also a subgroup and a topological group : $\Int(\lA)$ is not a topological subgroup of $\Aut(\lA)$. Then $\Int(\lA)$ is a Lie subgroup of $\Aut(\lA)$. Schematically, links between $\Int\lG$, $\ad\lG$, $\Aut\lG$ and $\partial\lG$ are
\begin{subequations}\label{eq:schem_ad_int}
\begin{align}
  \Int\lG&\longleftarrow\ad\lG\\
  \Aut\lG&\longrightarrow\partial\lG.
\end{align}
\end{subequations}
Remark that the sense of the arrows is important. By definition $\partial\lG$ is the Lie algebra of $\Aut\lG$, then there exist some algebras $\lG$ and $\lG'$ with $\Aut\lG\neq\Aut\lG'$ but with $\partial\lG=\partial\lG'$, because the equality of two Lie algebras doesn't implies the equality of the groups. The case of $\Int\lG$ and $\ad\lG$ is very different: the group is defined from the algebra, so that $\ad\lG=\ad\lG'$ implies $\Int\lG=\Int\lG'$ and $\Int\lG=\Int\lG'$ if and only if $\ad\lG=\ad\lG'$.

A result about the group of inner automorphism which will be useful later:

\begin{lemma}\label{lem:Int_g_gR}
If $\lG$ is a complex semisimple Lie algebra, then $\Int\lG=\Int\lG\heR$.
\end{lemma}

\begin{proof}
If $\{X_i\}$ is a basis of $\lG$, then $\{X_j,iX_j\}$ is a basis of $\lG\heR$. We define $\dpt{\psi}{\ad\lG}{\ad\lG\heR}$ by
\[
   \psi(\ad(a^jX_j))=\ad(a^jX_j).
\]
It is clearly surjective. On the other hand, if $\ad(a^jX_j)\ad(b^kX_k)$ as elements of $\ad\lG\heR$, then they are equals as elements of $\ad\lG$. The discussion following equations \eqref{eq:schem_ad_int} finishes the proof.
\end{proof}

\begin{corollary}
Any two Cartan involutions of a real semisimple Lie algebra are conjugate by an inner automorphism. \index{inner!automorphism}
\label{cor:Cartan_conj_inner}
\end{corollary}

\begin{proof}
Let $\sigma$ and $\sigma'$ be two Cartan involutions of $\lF$. We can find a $\varphi\in\inf\lF$ such that $[\varphi\sigma\varphi^{-1},\sigma']=0$. Thus it is sufficient to prove that any two Cartan involutions which commute are equals. So let us consider $\theta$ and $\theta'$, two Cartan involutions such that $[\theta,\theta']=0$. By lemma~\ref{lem:invol_compat}, we know that the decompositions into $+1$ and $-1$  eigenspaces with respect to $\theta$ and $\theta'$ are compatibles. If we consider $X\in\lF$ such that $\theta X=X$ and $\theta' X=-1$ (it is always possible if $\theta\neq\theta'$), we have
\[
\begin{split}
  0<B_{\theta}(X,X)=-B(X,\theta X)=-B(X,X)\\
  0<B_{\theta'}(X,X)=-B(X,\theta' X)=B(X,X)
\end{split}
\]
which is impossible.
\end{proof}

\begin{corollary}
Any two real compact form of a complex semisimple Lie algebra are conjugate by an inner automorphism.
\end{corollary}

\begin{proof}
    We know that any real form of $\lG$ induces an involution (the conjugation) and that if the real form is compact, the involution is Cartan on $\lG\heR$. Let $\lU_0$ and $\lU_1$ be two compact real forms of $\lG$ and $\tau_0$, $\tau_1$ the associated involutions of $\lG$ (which are Cartan involutions of $\lG\heR$). For a suitable $\varphi\in\Int\lG\heR$,
    \[
       \tau_0=\varphi\tau_1\varphi^{-1}.
    \]
    The fact that $\Int\lG=\Int\lG\heR$ (lemma~\ref{lem:Int_g_gR}) finishes the proof.
\end{proof}

\begin{proposition}
 The group $\Int(\lA)$ is a normal subgroup of $\Aut(\lA)$.
\end{proposition}

\begin{proof}
Let us consider a $s\in\Aut(\lA)$. The map $\dpt{\sigma_s}{\Aut(\lA)}{\Aut(\lA)}$, $\sigma_s(g)=sgs^{-1}$ is an automorphism of $\Aut(\lA)$. Indeed, consider $g$, $h\in\AutA$; direct computations show that $\sigma_s(gh)=\sigma_s(g)\sigma_s(h)$ and $[\sigma_s(g),\sigma_s(h)]=\sigma_s([g,h])$. From this, $(d\sigma_s)_e$ is an automorphism of $\partial(\lA)$, the Lie algebra of $\AutA$. For any $D\in\partial(\lA)$ we have
\begin{equation}\label{eq:ad_s_2}
 (d\sigma_s)_eD=\Dsdd{ sD(t)s^{-1} }{t}{0}
             =sDs^{-1}.
\end{equation}
Since $s$ is an automorphism of $\lA$ and $\ad(\lA)$, a subalgebra of $\gl(\lA)$,
\begin{equation}\label{eq:ad_s_1}
  s\ad Xs^{-1}=\ad(sX)
\end{equation}
for any $X\in\lA$, $s\in\Aut(\lA)$. Since $\ad(\lA)\subset\partial(\lA)$, we can write \eqref{eq:ad_s_2} with $D=\ad X$ and put it in \eqref{eq:ad_s_1}:
\[
   (d\sigma)_e\ad X=s\ad Xs^{-1}=\ad(s\cdot X).
\]
We know from general theory of linear operators on vector spaces that if $A,B$ are endomorphism of a vector space and if $A^{-1}$ exists, then $Ae^BA^{-1}=e^{ABA^{-1}}$. We write it with $A=s$ and $B=\ad X$:
\[
  \sigma_s\cdot e^{\ad X}=se^{\ad X}s^{-1}=e^{s\ad Xs^{-1}}=e^{\ad(s\cdot X)},
\]
sot that
\begin{equation}\label{eq:sigma_aut_s}
  \sigma_s\cdot e^{\ad X}=e^{\ad(s X)}.
\end{equation}

Ont the other hand, we know that $\IntA$ is connected, so it is generated by elements of the form $e^{\ad X}$ for $X\in\lA$. Then $\IntA$ is a normal subgroup of $\AutA$; the automorphism $s$ of $\lA$ induces the isomorphism $g\to sgs^{-1}$ in $\IntA$ because of equation \eqref{eq:sigma_aut_s}.
\end{proof}

More generally, if $s$ is an isomorphism from a Lie algebra $\lA$ to a Lie algebra $\lB$, then the map $g\to sgs^{-1}$ is an isomorphism between $\AutA$ and $\AutB$ which sends $\IntA$ to $\IntB$. Indeed, consider an isomorphism $\dpt{s}{\lA}{\lB}$ and $g\in\AutA$. If $g\in\IntA$, we have to see that $sgs^{-1}\in\IntB$. By definition, $\IntA$ is the analytic subgroup of $\GL(\lA)$ which has $\ad(\lA)$ as Lie algebra. We have $g=e^{\ad A}$, then $sgs^{-1}=e^{\ad(sA)}$ which lies well in $\IntB$.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Properties using the exponential}
%---------------------------------------------------------------------------------------------------------------------------



\begin{theorem}
Let $G$ and $H$ be two Lie groups and $\dpt{\varphi}{G}{H}$ a continuous homomorphism. Then $\varphi$ is analytic.
\end{theorem}

\begin{proof}
The Lie algebra of the product manifold $G\times H$ as $\lG\times\lH$ is given in~\ref{lemLeibnitz}. We define
\begin{equation}
  K=\{(g,\varphi(g)):g\in G\}\subset G\times H.
\end{equation}
It is clear that $K$ is closed in $G\times H$ because $G$ is closed and $\varphi$ is continuous.
By theorem~\ref{tho:diff_sur_ferme}, there exists an unique differentiable structure on $G\times H$ such that $K$ is a topological Lie subgroup of $G\times H$ (i.e.: Lie subgroup + induced topology). The Lie algebra of $K$ is
\begin{equation}
  \lK=\{(X,Y)\in\lG\times\lH:\forall t\in\eR, (e^{tX},e^{tY})\in K\}.
\end{equation}
Let $N_0$ be an open neighbourhood of $0$ in $\lH$ such that $\exp$ is diffeomorphic between $N_0$ and an open neighbourhood $N_e$ of $e$ in $H$. We define $M_0$ and $M_e$ in the same way, for $G$ instead of $H$. We can suppose $\varphi(M_e)\subset N_e$: if it is not, we consider a smaller $M_e$: the openness of $N_e$ and the continuity of $\varphi$ make it coherent.

The lemma~\ref{lem:sugroup_normal} allow us to consider $M_0$ and $N_0$ small enough to say that
\[
   \dpt{\exp}{(M_0\times N_0)\cap\lK}{(M_e\times N_e)\cap K}
\]
is diffeomorphic. Now, we are going to show that for any $X\in\lG$, there exists an unique $Y\in\lH$ such that $(X,Y)\in\lK$. The unicity is easy: consider $(X,Y_1),(X,Y_2)\in\lK$; then $(0,Y_1-Y_2)\in\lK$ (because a Lie algebra is a vector space). Then the definition of $\lK$ makes for any $t\in\eR$, $(e,\exp{t(Y_1-Y_2)})\in K$. Consequently, $\exp t(Y_1-Y_2)=\varphi(e)=e$ and then $Y_1-Y_2=0$.

In order to show the existence, let us consider a $r>0$ such that $X_r=(1/r)X$ keeps in $M_0$. This exists because the sequence $X_r\to 0$ (then it comes $M_0$ from a certain $r$). From the definitions, $\exp$ is diffeomorphic between $M_0$ and $M_e$, then $\exp X_r\in M_e$ and $\varphi(\exp X_r)\in N_e$ because $\varphi(M_e)\subset N_e$.

From this, there exists an unique $Y_r\in N_0$ such that $\exp Y_r=\varphi(\exp X_r)$ and an unique $Z_r\in(M_0\times N_0)\cap\lK$ satisfying  $\exp Z_r=(\exp X_r,\exp Y_r)$. But $\exp$ is bijective from $M_0\times N_0$, so that $Z_r=(X_r,Y_r)$ and we can choose $Y=rY_r$ as a $Y\in\lH$ such that $(X,Y)\in\lK$ (it is not really a choice: the unicity was previously shown). We denotes by $\dpt{\psi}{\lG}{\lH}$ the map which gives the unique $Y\in\lH$ associated with $X\in\lG$ such that $(X,Y)\in\lK$. This is a homomorphism between $\lG$ and $\lH$.

By definition, $(X,\psi(X))\in\lK$, i.e. $(\exp tX,\exp t\psi(X))\in K$ or
\begin{equation}
  \varphi(\exp tX)=\exp t\psi(X).
\end{equation}
Let us now consider a basis $\{X_1,\ldots,X_n\}$ of $\lG$. Since $\varphi$ is a homomorphism,
\begin{equation}\label{eq:coord_vp_exp}
   \varphi\big((\exp t_1X_1)(\exp t_2X_2)\ldots(\exp t_nX_n)\big)
     =\big(\exp t_1\psi(X_1)\big)\ldots\big( \exp t_n\psi(X_n) \big)
\end{equation}
Now, we apply lemma~\ref{lem:decomp} on the decomposition of $\lG$ into the $n$ subspace spanned by the $n$ vector basis (this is $n$ applications of the lemma), the map
\[
  (\exp t_1X_1)\ldots(\exp t_nX_n)\to (t_1,\ldots,t_n)
\]
is a coordinate system around $e$ in $G$. In this case, the relation \eqref{eq:coord_vp_exp} shows that $\varphi$ is differentiable at $e$. Then it is differentiable anywhere in $G$.
\end{proof}


\begin{proposition}
Let $G$ be a Lie group and $H$, a Lie subgroup of $G$ ($\lG$ and $\lH$ are the corresponding Lie algebras). We suppose that $H$ has at most a countable number of connected components. Then
\begin{equation}
  \lH=\{ X\in\lG:\forall t\in\eR,e^{tX}\in H \}
\end{equation}
\end{proposition}

\begin{proof}
We will once again use the lemma ~\ref{lem:decomp} with $\lN=\lH$ and $\lM$, a complementary vector space of $\lH$ in $\lG$. We define
\[
   V=\exp\mU_m\exp\mU_h
\]
where $\mU_m$ and $\mU_h$ are the sets given by the lemma. We consider on $V$ the induced topology from $G$. If we define
\[
   \mA=\{A\in\mU_m:e^{A}\in H\},
\]
we have
\begin{equation}\label{eq:union_A}
   H\cap V=\bigcup_{A\in\mA}e^{A}e^{\mU_h}.
\end{equation}
First, the definition of $V$ makes clear that the elements of the form $\exp A\exp\mU_h$ are in $V$. They are also in $H$ because $\exp A\in H$ (definition of $\mA$) and $\exp\mU_h$ still by definition. In order to see the inverse inclusion, let us consider a $h\in H\cap V$. We know that
\begin{equation}\label{eq:AB_to_exp}
(A,B)\to\exp A\exp B
\end{equation}
is a diffeomorphism between $\mU_m\times\mU_h$ and a neighbourhood of $e$ in $G$ which we called $V$. Thus any element of $V$ (\emph{a fortiori} in $V\cap H$) can be written as $\exp A\exp B$ with $A\in\mU_m$ and $B\in\mU_h$. Then $h=e^Ae^B$ for some $A\in\mU_m$, $B\in\mU_h$. Since $H$ is a group and $e^B\in H$, in order the product to belongs to $H$, $e^A$ must lies in $H$: $A\in\mA$.

\begin{remark}\label{rem:union_disj}
Note that since \eqref{eq:AB_to_exp} is diffeomorphic, the union in right hand side of \eqref{eq:union_A} is disjoint. Each member of this union is a neighbourhood in $H$ because it is a set $h\exp\mU_h$ where $\exp\mU_h$ is a neighbourhood of $e$ in $H$.
\end{remark}

Now we consider the map $\dpt{\pi}{V}{\mU_m}$,
\[
  \pi(e^{X}e^Y)=X
\]
if $X\in\mU_m$ and $Y\in\mU_h$. This is a continuous map which sends $H\cap V$ into $\mA$. The identity component of $H\cap V$ (in the sense of topology of $V$) is sent to a countable subset of $\mU_m$. Indeed by remark~\ref{rem:union_disj}, identity component of $H\cap V$ is only one of the terms in the union \eqref{eq:union_A}, namely $A=0$. But we know that $\pi^{-1}(o)=\exp\mU_h$, thus $\exp\mU_h$ is the identity component of $H\cap V$ for the topology of $V$.
\end{proof}


\begin{theorem}
Let $G$ be a Lie group and $H$, a Lie subgroup of $G$.
\begin{enumerate}
\item If $H$ is a topological Lie subgroup of $G$, then it is closed in $G$,
\item If $H$ has at most a countable number of connected components and is closed in $G$, then $H$ is a topological subgroup of $G$.
\end{enumerate}
\label{tho:H_ferme}
\end{theorem}

\begin{proof}
\subdem{First point} It is sufficient to prove that if a sequence $h_n\in H$ converges (in $G$) to $g\in G$, then $g\in H$ (this is almost the definition of a closed subset). We consider $V$, a neighbourhood of $0$ in $\lG$ such that

\begin{itemize}
\item $\exp$ is diffeomorphic between $V$ and an open neighbourhood  of $e$ in $G$,
\item $\exp(V\cap \lH)=(\exp V)\cap H$.
\end{itemize}
This exists by the lemma~\ref{lem:sugroup_normal}; we can suppose that $V$ is bounded. Consider $\mU$, an open neighbourhood of $0$ in $\lG$ contained in $V$ such that $\exp-\mU\exp\mU\subset\exp V$.

Since $h_n\to g$, there exists a $N\in\eN$ such that $n\geq N$ implies $h_n\in g\exp\mU$ (i.e $h_n$ is the product of $g$ by an element rather close to $e$; since the multiplication is differentiable, the notion of ``not so far''\ is good to express the convergence notion). From now we only consider such elements in the sequence. So, $h_N^{-1} h_n\in(\exp V)\cap H$ ($n\geq N$) because
\[
   h_N^{-1} h_n\in\exp-\mU g^{-1} g\exp\mU\subset\exp V.
\]
(note that $H$ is a group, then $h_i^{-1}\in H$) From the second point of the definition of $V$, there exists a $X_n\in V\cap\lH$ such that $h^{-1}_N h_n=\exp X_n$ for any $n\geq N$.

Since $V$ in bounded, there exists a subsequence out of $(X_i)$ (which is also called $X_i$) converging to a certain $Z\in\lG$. But $\lH$ is closed in $\lG$ because it is a vector subspace (we are in a finite dimensional case), then $Z\in\lH$ and thus the sequence $(h_i)$ converges to $h_N\exp Z$; therefore $g\in H$.

\subdem{Second point} The subgroup $H$ is closed in $G$ and has a countable number of connected component. Since $H$ is closed, theorem~\ref{tho:diff_sur_ferme} it has an analytics structure for which it is a topological Lie subgroup of $G$. We denotes by $H'$ this Lie group.

The identity map $\dpt{I}{H}{H'}$ is continuous\quext{pourquoi ?} (see error~\ref{err:gross}). Thus any connected component of $H$ is contained in a connected component of $H'$, the it has only a countable number of connected components. By corollary~\ref{cor:top_subgroup}, $H=H'$ as Lie group.

\end{proof}

Now we take back our example with $G=S^1\times S^1$, $H=\gamma(\eR)$. In this case, the theorem doesn't works. Let us see why as deep as possible. We have $\lG=\eR\oplus\eR=\eR^2$ and $\lH=\eR$, a one-dimensional vector subspace of $\lG$. ($\lH$ is a ``direction ''\ in $\lG$) First, we build the neighbourhood $V$ of $0$ in $\lG$. It is standard to require that $\exp$ is diffeomorphic between $V$ and an open around $(1,1)\in S^1\times S^1$. It also must satisfy $e^{V\cap\lH}=e^V\cap H$. This second requirement is impossible.

Intuitively. We can see $V\subset\lG$ as a little disk tangent to  the torus. The exponential map deposits it on the torus, as well that $e^V$ covers a little area on $G$. Then $e^V\cap H$ is one of these amazing open subset of $\Gamma$ which are dense in a certain domain of $G$.

On the other hand, $V\cap\lH$ is just a little vector in $\lH$; the exponential deposits it on a small line in $G$. This is not the same at all. Then lemma~\ref{lem:sugroup_normal} fails in our case. Let us review the proof of this lemma until we find a problem.

Let $W_0\subset\lG$  be a neighbourhood of $0$ which is in bijection with an open around $e$ in $G$. We consider $N_0$, an open subset of $H$ such that $N_0\subset W_0$ and $N_0$ is in bijection with $N_e$, a neighbourhood of $e$ in $G$. Until here, no problems. But now the proof says that there exists an open $U_e$ in $G$ such that $N_e=U_e\cap H$. This is false in our case. Indeed, $N_e=e^{N_0}$ is just a segment in $G$ while any subset of $G$ of the form $U_e\cap H$ is an ``amazing''\ open.

So we see that deeply, the obstruction for a Lie subgroup to be a topological Lie subgroup resides in the fact that the topology of a submanifold is \emph{more} than the induced topology, so that we can't automatically find the open $U_e$ in $G$.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Compact Lie algebra}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{pg:compact_Lie}

We consider $\lG$, a real Lie algebra and $\lH$, a subalgebra of $\lG$. Let $K^*$ be the analytic subgroup of $\Int(\lG)$ which corresponds to the subalgebra $\ad_{\lG}(\lH)$ of $\ad_{\lG}(\lG)$.

\begin{definition}
We say that $\lH$ is \defe{compactly embedded}{compactly embedded} in $\lG$ if $K^*$ is compact. A Lie algebra is \defe{compact}{compact!Lie algebra}\index{Lie!algebra!compact} when it is compactly embedded in itself.
\end{definition}

The analytic subgroup of $\Int(\lG)$ which corresponds to $\ad_{\lG}(\lG)$, by definition, is $\Int(\lG)$. Then the compactness of $\lG$ is the one of $\Int(\lG)$.

\begin{remark}
The compactness notion on a Lie group is defined from the topological structure of the Lie group seen as a manifold. It is all but trivial that the compactness on a Lie group is related to the compactness on its Lie algebra; the proposition~\ref{prop:alg_grp_compact} will however make the two notions related in the natural way.
\end{remark}

\begin{remark}
The topology on $K^*$ is not necessary the same as the induced one from $\Int(\lG)$ and $\Int(\lG)$ has also not necessary the induced topology from $\GL(\lG)$. However the next proposition will show that the compactness notion is well the one induced from $\GL(\lG)$.
\end{remark}

\begin{proposition}
We consider $\tK$, the same set and group as $K^*$, but with the induced topology from $\GL(\lG)$. Then $\tK$ is compact if and only if $K^*$ is compact.
\end{proposition}

Note however that $K^*$ and $\tK$ are not automatically the same as manifold.

\begin{proof}
\subdem{$K^*$ compact implies $\tK$ compact}
The identity map $\dpt{\iota}{K^*}{\GL(\lG)}$ is analytic, and then is continuous because $\Int(\lG)$ is by definition an analytic subgroup of $\GL(\lG)$ and $K^*$ an analytic subgroup of $\Int(\lG)$. If we have a covering of $\tK$ with open set $\mO_i\cap\tK$ of $\tK$ ($\mO_i$ is open in $\GL(\lG)$), the continuity of $\iota$ make the finite subcovering of $K^*$ good for $\tK$.
\subdem{$\tK$ compact implies $K^*$ compact}
If $\tK$ is compact, then it is closed in $\GL(\lG)$. As set, $K^*$ is closed in $\GL(\lG)$ and by definition it is connected. Then by the theorem~\ref{tho:H_ferme}, $K^*$ is a topological subgroup of $\GL(\lG)$. Consequently, $K^*$ and $\tK$ are homeomorphic and they have same topology.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
    If $G$ is a compact group in $\GL(n,\eR)$, then there exists a $G$-invariant quadratic form on $\eR^n$\quext{Is it true ? I've not even found a precise statement of this claim.}.
\end{lemma}

\begin{proposition}     \label{ProplGcompactKillNeg}
Let $\lG$ be a real Lie algebra.

\begin{enumerate}
\item If $\lG$ is semisimple, then $\lG$ is compact if and only if  the Killing form is strictly negative definite.
\item If it is compact then it is a direct sum
\begin{equation}
   \lG=\mZ\oplus [\lG,\lG]
\end{equation}
where $\mZ$ is the center of $\lG$ and the ideal $[\lG,\lG]$ is compact and semisimple.
\end{enumerate}
\label{prop:compact_Killing}
\end{proposition}

\begin{proof}
\subdem{If the Killing form is nondegenerate}
We consider $\lG$, a Lie algebra whose Killing form is strictly negative definite. Up to some dilatations (and a sign), this is the euclidian metric. Then $O(B)$, the group of linear transformations which leave $B$ unchanged is compact in the topology of $\GL(\lG)$: this is almost the rotations. From equation \eqref{eq:Aut_Iso}, $\Aut(\lG)\subset O(B)$. With this, $\Aut(\lG)$ is closed in a compact, then it is compact. Then $\Int(\lG)$ is closed in $\Aut(\lG)$ --here is the assumption of semi-simplicity-- and $\Int(\lG)$ is compact.
\subdem{If $\lG$ is compact}
Since $\lG$ is compact, $\Int(\lG)$ is compact in the topology of $\Aut(\lG)$; then there exists an $\Int(\lG)$-invariant quadratic form $Q$. In a suitable basis $\{X_1,\ldots,X_n\}$ of $\lG$, we can write this form as
\[
   Q(X)=\sum x_i^2
\]
for $X=\sum x_iX_i$. In this basis the elements of $\Int(\lG)$ are orthogonal matrices and the matrices of $\ad(\lG)$ are skew-symmetric matrices (the Lie algebra of orthogonal matrices). Let us consider a $X\in\lG$ and denote by $a_{ij}(X)$ the matrix of $\ad(X)$. We have
\begin{equation}
\begin{split}
  B(X,X)=\tr(\ad X\circ\ad X)
        =\sum_i\sum_ja_{ij}(X)a_{ji}(X)
    =-\sum_{ij}a_{ij}(X)^2\leq 0.
\end{split}
\end{equation}
Then the Killing form is negative definite\footnote{Here we use ``negative definite''\ and ``\emph{strictly} negative definite''; in some literature, the terminology is slightly different and one says ``\emph{semi} negative definite''\ and ``negative definite''.}. On the other hand, $B(X,X)=0$ implies $\ad(X)=0$ and $X\in\mZ(\lG)$. Thus $\lG^{\perp}\subset\mZ$. If $\lG$ is semisimple, this center is zero; this conclude the first item of the proposition.

Now $\mZ$ is an ideal and corollary~\ref{cor:decomp_ideal} decomposes $\lG$ as
\begin{equation}
  \lG=\mZ\oplus\lG'.
\end{equation}
Let us suppose that the restriction of $B$ to $\lG'\times\lG'$ is actually the Killing form on $\lG'$ (we will prove it below). Then the Killing form on $\lG'$ is strictly negative definite; then $\lG'$ is compact.

Now we prove that the Killing form on $\lG$ descent to the Killing form on~$\lG'$. Remark that $\mZ$ is invariant under all the automorphism. Indeed consider $Z\in\mZ$, i.e.  $[X,Z]=0$. If $\sigma$ is an automorphism,
\[
   [X,\sigma Z]=\sigma[\sigma^{-1} X,Z]=0.
\]
Here the difference between $\Int(\lG)$ and $\Aut(\lG)$ is the fact that $\Int(\lG)$ is compact; then we can construct a $\Int(\lG)$-invariant quadratic form $Q$, but not a $\Aut(\lG)$-invariant one. We consider an orthogonal complement (with respect to $Q$) $\lG'$ of $\mZ$:
\begin{equation}
   \lG=\lG'\oplus_{\perp}\mZ.
\end{equation}
The algebra $\lG'$ is also invariant because for any $Z\in\mZ$,
\[
Q(Z,\sigma X)=Q(\sigma^{-1}(Z),X)=0.
\]
It is also clear that $\mZ$ is invariant under $\ad\lG$ because $(\ad X)Z=0$. Finally $\lG'$ is invariant as well under $\ad(\lG)$. Indeed $a\in\ad(\lG)$ can be written as $a=a'(0)$ for a path $a(t)\in\Int(\lG)$. We identify $\lG$ and his tangent space (as vector spaces),
\[
  aX=\Dsdd{ a(t)X }{t}{0}.
\]
If $X\in\lG'$, $a(t)X\in\lG'$ for any $t$ because $\lG'$ is invariant under $\Int(\lG)$\footnote{As physical interpretation, if something is invariant under a group of transformations, it is invariant under the infinitesimal transformations as well.}. Thus $a(t)X$ is a path in $\lG'$ and his derivative is a vector in $\lG'$.

All this make $\lG'$ an ideal in $\lG$; then the Killing form descent by lemma~\ref{lem:Killing_descent_ideal}. Now if $X\in\lG$, we have
\begin{equation}
  B(X,X)=\tr(\ad X\circ\ad X)
        =\sum_{ij}a_{ij}(X)a_{ji}(X)
    =-\sum_{ij}a_{ij}(X)^2;
\end{equation}
then $B(X,X)\leq 0$ and the equality holds if and only if $\ad X=0$ i.e. if and only if $X\in\mZ$. Thus $B$ is strictly negative definite on $\lG'$.

Up to now we have proved that $\lG'$ is semisimple (because $B$ is nondegenerate) and compact (because $B$ is strictly negative definite).

It remains to be proved that $\lG'=[\lG,\lG]=\dD(\lG)$. From corollary~\ref{cor:decomp_ideal}, $\dD\lG$ has a complementary $\lA$ which is also an ideal: $\lG=\dD\lG+\lA$. Then $[\lG,\lA]\subset\dD\lG$ and $[\lG,\lA]\subset\lA\cap\dD\lG:\{0\}$. Then $\lA\subset\mZ$, so that
\begin{align}\label{eq:G_Z_B}
   \lG=\mZ+\dD\lG&&\text{(non direct sum)}.
\end{align}
Now we have to prove that the sum is actually direct. The ideal $\mZ$ has a complementary ideal $\lB$: $\lG=\mZ\oplus\lB$ and
\[
   \dD\lG=[\lG,\lG]\subset\underbrace{[\lG,\mZ]}_{=0}+[\lG,\lB]\subset\lB.
\]
Then $\dD\lG\subset\lB$ which implies that $\dD\lG\cap\mZ=\{0\}$ because the sum $\lG=\mZ\oplus\lB$ is direct. Then the sum \eqref{eq:G_Z_B} is direct.

\end{proof}

\begin{proposition}
A real Lie algebra $\lG$ is compact if and only if one can find a compact Lie group $G$ which Lie algebra is isomorphic to $\lG$.
\label{prop:alg_grp_compact}
\end{proposition}

\begin{proof}
\subdem{Direct sense} Since $\lG$ is compact, $\lG=\mZ\oplus\dD\lG$ with $\dD\lG=\lG'$ compact and semisimple; in particular, the center of $\lG'$ is $\{0\}$. Since $\mZ$ is compact and abelian, it is isomorphic to the torus $S^1\times\ldots\times S^1$. Since $\lG'$ is compact, $\Int(\lG')$ is compact, but the Lie algebra if $\Int(\lG')$ is --by definition--  $\ad(\lG')$. The center of a semisimple Lie algebra is zero; then $\ad X'=0$ implies $X=0$ (for $X\in\lG'$). Then $\ad$ is an isomorphism between $\lG'$ and $\ad\lG'$.

All this shows that --up to isomorphism-- $\mZ$ and $[\lG,\lG]$ are Lie algebras of compact groups. We know from lemma~\ref{lemLeibnitz} that the Lie algebra of $G\times H$ is $\lG\oplus\lH$. Thus, here, $\lG$ is the Lie algebra of the compact group $S^1\times\ldots\times S^1\times\Int(\lG)$.
\subdem{Reverse sense}
We consider a compact group $G$ and we have to see the its Lie algebra $\lG$ is compact. If $G$ is connected, $\Ad_G$ is an analytic homomorphism from $G$ to $\Int(\lG)$. If $G$ is not connected, the Lie algebra of $G$ is $T_eG_0$ ($G_0$ is the identity component of $G$) where $G_0$ is connected and compact because closed in a compact.
\end{proof}

\begin{proposition}
Let $\lG$ be a real Lie algebra and $\mZ$, the center of $\lG$. We consider $\lK$, a compactly embedded in $\lG$. If $\lK\cap\mZ=\{0\}$ then the Killing form of $\lG$ is strictly negative definite on $\lK$.
\label{prop:K_Z_Killing}
\end{proposition}

\begin{proof}
Let $B$ be the Killing form on $\lG$ and $K$ the analytic subgroup of $\Int(\lG)$ whose Lie algebra is $\ad_{\lG}(\lK)$. By assumption, $K$ is a compact Lie subgroup of $\GL(\lG)$. Then there exists a quadratic form on $\lG$ invariant under $K$, and a basis in which the endomorphisms $\ad_{\lG}(T)$ for $T\in\lK$ are skew-symmetric because the matrices of $K$ are orthogonal. If the matrix of $\ad T$ is $(a_{ij})$, then
\begin{equation}
   B(T,T)=\sum_{ij}a_{ij}(T)a_{ji}(T)
         =-\sum_{ij}a_{ij}^2(T)\leq 0,
\end{equation}
and the equality hold only if $\ad T=0$ i.e. if $T\in\mZ$. From the assumptions, $\lK\cap\mZ=\{0\}$; then $B(T,T)=0$ if and only if $T=0$.
\end{proof}

\section{Real Lie algebras}
%++++++++++++++++++++++++++

\subsection{Real and complex vector spaces}
%//////////////////////////////////////////////

If $V$ is a real vector space, the \defe{complexification}{complexification!of a vector space} of $V$ is the vector space\nomenclature{$V\heC$}{Complexification of $V$}
\[
  V\heC:=V\otimes\beR\eC.
\]
If $\{v_i\}$ is a basis of $V$ on $\eR$, then $\{v_i\otimes 1\}$ is a basis of $V\heC$ on $C$. Then
\[
   \dim_{\eR}V=\dim_{\eC}V\heC.
\]

Let $W$ be a complex vector space. If one restrains the scalars to $\eR$, we find a real vector space denoted by $W\heR$\nomenclature{$W\heR$}{Restriction of a complex vector spaces to $\eR$}. If $\{w_j\}$ is a basis of $W$, then $\{w_j,iw_j\}$ is a basis of $W\heR$ and
\[
  \dim\beC W=\frac{1}{2}\dim\beR W\heR.
\]
Note that $(V\heC)\heR=V\oplus iV$.

A real vector space $V$ is a \defe{real form}{real!form!of complex vector space} of a complex vector space $W$ if $W\heR=V\oplus iV$. If $V$ is a real form of $W$, the map $\dpt{\varphi}{V\heC}{V\heC}$ given by the identity on $V$ and the multiplication by $-1$ on $iV$ is the \defe{conjugation}{conjugation} of $V\heC$ with respect of the real form $V$.

\subsection{Real and complex Lie algebras}
%/////////////////////////////////////////

For notational convenience, if not otherwise mentioned, $\lG$ will denote a complex Lie algebra and $\lF$ a real one. If $\lF$ is a real Lie algebra and $\lF\heC=\lF\otimes\eC$, its complexification (as vector space), we endow $\lF\heC$ with a Lie algebra structure by defining
\[
  [ (X\otimes a),(Y\otimes b)  ]=[X,Y]\otimes ab.
\]
This is a bilinear extension of the Lie algebra bracket of $\lF$. It is rather easy to see that $[\lF,\lF]\heC=[\lF\heC,\lF\heC]$.

Now we turn our attention to the Killing form. Let $\lF$ be a real Lie algebra with a Killing form $B\blF$. A basis of $\lF$ is also a basis of $\lF\heC$. Then the matrix $B_{ij}=\tr( \ad X_i\circ\ad X_j )$ of the Killing form is the same for $\lF\heC$ than for $\lF$. In conclusion:
\[
   B_{\lF\heC}|_{\lF\times\lF}=B\blF.
\]

Let us study the inverse process: $\lG$ is a complex Lie algebra and $\lG\heR$ is the real Lie algebra obtained from $\lG$ by restriction of the scalars. If $\mB=\{v_j\}$ is a basis of $\lG$, $\mB'=\{v_j,iv_j\}$ is a one of $\lG\heR$. For a certain $X\in\lG$ we denote by $(c_{kl})$ the matrix of $\ad_{\lG}X$. Now we study the matrix of $\ad_{\lG\heR}X$ in the basis $\mB'$ by computing
\begin{equation}
(\ad_{\lG}X)v_i=c_{ik}v_k
               =\big[ \real(c_{ik})+i\imag(c_{ik}) \big]v_k
           =a_{ik}v_k+b_{ik}(iv_k)
\end{equation}
if $a=\real c$ and $b=\imag c$. Then the columns of $\ad_{\lG\heR}$ which correspond to the $v_i\in\mB'$'s are given by
\[
\ad_{\lG\heR}X=\begin{pmatrix}
                 a&\cdot\\
         b&\cdot
               \end{pmatrix}
\]
where the dots denote some entries to be find now:
\begin{equation}
(\ad_{\lG}X)(iv_i)=i\big(  a_{ik}v_k+b_{ik}(iv_k)  \big)\\
                  =a_{ik}(iv_k)-b_{ik}v_k,
\end{equation}
so that the complete matrix of $\ad_{\lG\heR}X$ in the basis $\mB'$ is given by
\[
\ad_{\lG\heR}X=\begin{pmatrix}
                 a&-b\\
         b&a
               \end{pmatrix}.
\]
So,
\[
\ad_{\lG\heR}X\circ\ad_{\lG\heR}X'=\begin{pmatrix}
                 aa'-bb'&\cdot\\
         \cdot&aa'-bb'
               \end{pmatrix}.
\]
Then $B(X,X')=2\tr(aa'-bb')$ while
\begin{equation}
  B(X,Y)=\tr\big(  (a+ib)(a'+ib')  \big)\\
        =\tr(aa'-bb')+i\tr(ab'+ba').
\end{equation}
Thus we have
\begin{equation}
     B_{\lG\heR}=2\real B_{\lG},
\end{equation}
so that $\lG\heR$ is semisimple if and only if $\lG$ is semisimple.

\subsection{Split real form}
%//////////////////////////////

Let $\lG$ be a complex semisimple Lie algebra, $\lH$ a Cartan subalgebra, $\Phi$ the set roots, $\Delta$ the set of non zero roots and $B$, the Killing form. From property \eqref{eq:enuaiv} and the fact that $c(-\alpha,-\beta)=c(\alpha,\beta)$, we find $c(\alpha,\beta)^2=\frac{1}{2}\lbha(1+\lbba)|\alpha|^2$,
 so that $c(\alpha,\beta)^2\geq 0$ which gives $c(\alpha,\beta)\in\eR$. We can define

\[
   \lGeR=\lH_0\bigoplus_{\alpha\in\Phi}\eR x_{\alpha}.
\]
Remark that $\lG_{\alpha}$ has dimension one with respect to $\eC$, not $\eR$; then $\eR x_{\alpha}\neq\lG_{\alpha}$, but $\eC x_{\alpha}=\lG_{\alpha}$ and $\lG_{\alpha}=\eR x_{\alpha}\oplus i\eR x_{\alpha}$. Since it is clear that $\bigoplus_{\alpha\in\Delta}( \eR x_{\alpha}\oplus i\eR x_{\alpha} )=\bigoplus_{\alpha\in\Delta}\lG_{\alpha}$, the proposition~\ref{prop:lHeR} gives
\begin{equation}
  \lG=\lGeR\oplus i\lGeR.
\end{equation}
Any real form of $\lG$ which contains the $\lHeR$ of a certain Cartan subalgebra $\lH$ of $\lG$ is said a \defe{split real form}{split!real form}. The construction shows that any complex semisimple Lie algebra admits a split real form.

\subsection{Compact real form}
%///////////////////////////////

A \defe{compact real form}{compact!real form}\index{compact!Lie algebra} of a complex Lie algebra is a real form which is compact as Lie algebra. Recall that a real Lie algebra is compact when its analytic group of inner automorphism is compact, see page \pageref{pg:compact_Lie}

\begin{theorem}
Any complex semisimple Lie algebra contains a compact real form.
\end{theorem}

\begin{proof}
Let $\lH$ be a Cartan algebra of the complex semisimple Lie algebra $\lG$ and $ x_{\alpha}$, some root vectors. We consider the space
\begin{equation}
 \lU_0=\underbrace{\sum_{\alpha\in\Phi}\eR ih_{\alpha}}_A+\underbrace{\sum_{\alpha\in\Phi}\eR( x_{\alpha}-\xbma)}_B+\underbrace{\sum_{\alpha\in\Phi}\eR i( x_{\alpha}+\xbma)}_C.
\end{equation}
Since $\lU_0\oplus i\lU_0$ contains all the $\eC h_{\alpha}$, $\lH\subset\lU_0\oplus i\lU_0$; it is also rather clear that $\lU_0$ is a real form of $\lG$ (as vector space), for example, $i\eR( x_{\alpha}-\xbma)+\eR i( x_{\alpha}+\xbma)=\eR i x_{\alpha}$. Now we have to check that $\lU_0$ is a real form of $\lG$ as Lie algebra, i.e. that $\lU_0$ is closed for the Lie bracket. This is a lot of computations:
\[
\begin{split}
[i h_{\alpha},i\hbb]               &=0,\\
[i h_{\alpha},( x_{\alpha}-\xbma)]        &=i(\alpha( h_{\alpha}) x_{\alpha}-(-\alpha)( h_{\alpha})\xbma)\\
                            &=i\alpha( h_{\alpha})( x_{\alpha}+\xbma)\in C,\\
[i h_{\alpha},i( x_{\alpha}+\xbma)]       &=-\alpha( h_{\alpha})( x_{\alpha}-\xbma)\in B,\\
[( x_{\alpha}-\xbma),(\xbb-\xbmb)] &=c(\alpha,\beta)( x_{\alpha+\beta}-x_{-(\alpha+\beta)} )\in B\\
                            &\quad -c(\alpha,\beta)(x_{\alpha-\beta}-x_{\beta-\alpha})\in B,\\
[( x_{\alpha}-\xbma),i(\xbb+\xbmb)]&=ic(\alpha,\beta)(x_{\alpha+\beta}+x_{-(\alpha+\beta)})\in C\\
                            &\quad +ic(\alpha,-\beta)(x_{\alpha-\beta)}+x_{-\alpha+\beta})\in C\\
[i h_{\alpha},(\xbb-\xbmb)]     &=i\beta( h_{\alpha})(\xbb-\xbmb)\in C\\
[i h_{\alpha},i(\xbb+\xbmb)]       &=-\beta( h_{\alpha})(\xbb-\xbmb)\in B\\
[i( x_{\alpha}+\xbma),i(\xbb+\xbmb)]&=-c(\alpha,\beta)(x_{\alpha+\beta}-x_{-(\alpha+\beta)})\\
                             &\quad -c'(\alpha,-\beta)(x_{\alpha-\beta}-x_{-\alpha+\beta}).
\end{split}
\]

From proposition~\ref{prop:compact_Killing}, it just remains to prove that the Killing form of $\lU_0$ is strictly negative definite. We know that $B_{\lG}(\lG_{\alpha},\lG_{\beta})=0$ if $\alpha,\beta\in\Phi$ and $\alpha+\beta\neq 0$; then $A\perp B$ and $A\perp C$. It is a lot of computation to compute the Killing form; we know that $B$ is strictly positive definite on $\sum_{\alpha\in\Delta}\eR h_{\alpha}$ (and then strictly negative definite on $A$) a part this, the non zero elements are (recall that if $\alpha\neq 0$, $B( x_{\alpha}, x_{\alpha})=0$ from corollary~\ref{cor:Bxy_zero})
\[
\begin{split}
  B( ( x_{\alpha}-\xbma),( x_{\alpha}-\xbma) )&=-2B( x_{\alpha},\xbma)=-2\\
  B(i( x_{\alpha}+\xbma),i( x_{\alpha},\xbma))&=-2.
\end{split}
\]

What we have in the matrix of $B_{\lG}|_{\lU_0\times\lU_0}$ is a negative definite block (corresponding to $A$), $-2$ on the rest of the diagonal and zero anywhere else. Then it is well negative definite and $\lU_0$ is a compact real from of $\lG$.
\end{proof}

\subsection{Involutions}
%//////////////////////////

Let $\lG$ be a (real or complex) Lie algebra. An automorphism $\dpt{\sigma}{\lG}{\lG}$ which is not the identity such that $\sigma^2$ is the identity is a \defe{involution}{involutive!automorphism}. An involution $\dpt{\theta}{\lF}{\lF}$ of a \emph{real} semisimple Lie algebra $\lF$ such that the quadratic form $B_{\theta}$ defined by
\[
   B_{\theta}(X,Y):=-B(X,\theta Y)
\]
is positive definite is a \defe{Cartan involution}{Cartan!involution}.

\begin{proposition}
Let $\lG$ be a complex semisimple Lie algebra, $\lU_0$ a compact real form and $\tau$, the conjugation of $\lG$ with respect to $\lU_0$. Then $\tau$ is a Cartan involution of $\lG\heR$.
\label{prop:conj_invol}
\end{proposition}

\begin{proof}
From the assumptions, $\lG=\lU_0\oplus i\lU_0$, $\tau_{\lU_0}=id$ and $\tau_{i\lU_0}=-id$; then it is clear that $\tau_{\lG\heR}^2=id|_{\lG\heR}$. If $Z\in\lG$, we can decompose into $Z=X+iY$ with $X$, $Y\in\lU_0$. For $Z\neq 0$, we have
\begin{equation}
    B_{\lG}(Z,\tau Z)=B_{\lG}(X+iY,X-iY)
                     =B_{\lG}(X,X)+B_{\lG}(Y,Y)
             =B_{\lU_0}(X,X)+B_{\lU_0}(Y,Y)<0
\end{equation}
because $B$ restricts itself to $\lU_0$ which is compact. Then
\begin{equation}
  (B_{\lG\heR})_{\tau}(Z,Z')=B_{\lG\heR}(Z,\tau Z)
                            =-2\real B_{\lG}(Z,\tau Z')
\end{equation}
is positive definite because $(B_{\lG})_{\tau}$ is negative definite. Thus $\tau$ is a Cartan involution of $\lG\heR$.
\end{proof}

\begin{lemma}
If $\varphi$ and $\psi$ are involutions of a vector space $V$ (we denote by $V_{\psi^+}$ and $V_{\psi^-}$ the subspaces of $V$ for the eigenvalues $1$ and $-1$ of $\psi$ and similarly for $\varphi$), then
\[
[\varphi,\psi]=0\quad\text{iff}\quad \left\{   \begin{aligned}
                                                   V_{\varphi^+}&=(V_{\varphi^+}\cap V_{\psi^+})\oplus(V_{\varphi^+}\cap V_{\psi^-})\\
                           V_{\varphi^-}&=(V_{\varphi^-}\cap V_{\psi^+})\oplus(V_{\varphi^-}\cap V_{\psi^-}),
                                           \end{aligned}
                      \right.
\]
i.e. if and only if the decomposition of $V$ with respect to $\varphi$ is ``compatible''{} with the one with respect to $\psi$.
\label{lem:invol_compat}
\end{lemma}

\begin{proof}
\subdem{Direct sense}
Let us first see that $\varphi$ leaves the decomposition $V=V_{\psi^+}\oplus V_{\psi^-}$ invariant. If $x=x_{\psi^+}+x_{\psi^-}$,
\[
   \varphi(x_{\psi^+})=(\varphi\circ\psi)(x_{\psi^+})=(\psi\circ\varphi)(x_{\psi^+}).
\]
Then $\varphi(x_{\psi^+})\in V_{\psi^+}$, and the matrix of $\varphi$ is block-diagonal with respect to the decomposition given by $\psi$. Thus $V_{\psi^+}$ and $V_{\psi^-}$ split separately into two parts with respect to $\varphi$.

\subdem{Inverse sense}
If $x\in V$, we can write $x=x_{++}+x_{+-}+x_{-+}+x_{--}$ where the first index refers to $\psi$ while the second one refers to $\psi$; for example, $x_{+-}\in V_{\psi^+}\cap V_{\varphi^-}$. The following computation is easy:
\begin{equation}
\begin{split}
(\varphi\circ\psi)(x)&=\varphi(x_{++}+x_{+-}-x_{-+}-x_{--})\\
                 &=x_{++}-x_{+-}-x_{-+}+x_{--}\\
         &=\psi(x_{++}-x_{+-}-x_{-+}-x_{--})\\
         &=(\psi\circ\varphi)(x).
\end{split}
\end{equation}
\end{proof}

\begin{theorem}
Let $\lF$ be a real semisimple Lie algebra, $\theta$ a Cartan involution on $\lF$ and $\sigma$, another involution (not specially Cartan). Then there exists a $\varphi\in\Int\lF$ such that $[\varphi\theta\varphi^{-1},\sigma]=0$
\label{tho:sigma_theta_un}
\end{theorem}

\begin{proof}
If $\theta$ is a Cartan involution, then $B_{\theta}$ is a scalar product on $\lF$. Let $\omega=\sigma\theta$. By using $\sigma^2=\theta^2=1$, $\theta=\theta^{-1}$ and the invariance property~\ref{prop:auto_2} of the Killing form,
\begin{equation}
B(\omega X,\theta Y)=B(X,\omega^{-1}\theta Y)
                    =B(X,\theta\sigma\theta Y)
            =B(X,\theta\omega Y).
\end{equation}
Then $B_{\theta}(\omega X,Y)=B_{\theta}(X,\omega Y)$. This is a general property of scalar product that in this case, the matrix of $\omega$ is symmetric while the one of $\omega^2$ is positive definite. If we consider the classical scalar product whose matrix is $(\delta_{ij})$, the property is written as $A_{ij}v_jw_j=v_iA_{ij}w_j$ (with sum over $i$ and $j$); this implies the symmetry of $A$. To see that $A^2$ is positive definite, we compute (using the symmetry):
\[
   A_{ij}A_{jk}v_iv_k=v_iA_{ij}v_kA_{kj}=\sum_j(v_iA_{ij})^2>0.
\]
The next step is to see that there is an unique linear transformation $\dpt{A}{\lF}{\lF}$ such that $\omega^2=e^A$, and that for any $t\in\eR$, the transformation $e^{tA}$ is an automorphism of $\lF$.

We choose an orthonormal (with respect to the inner product $B_{\theta}$) basis $\{X_1,\ldots,X_n\}$  of $\lF$ in which $\omega$ is diagonal. In this basis, $\omega^2$ is also diagonal and has positive real numbers on the diagonal; then the existence and unicity of $A$ is clear. Now we take some notations:
\begin{subequations}
\begin{align}
  \omega(X_i)&=\lambda_iX_i\\
  \omega^2(X_i)&=e^{a_i}X_i,
\end{align}
\end{subequations}
(no sum at all) where the $a_i$ are the diagonals elements of $A$. The structure constants are as usual defined by
\begin{equation}
   [X_i,X_j]=c_{ij}^kX_k.
\end{equation}
Since $\sigma$ and $\theta$ are automorphisms, $\omega^2$ is also one. Then
\[
\omega^2[X_i,X_j]=c_{ij}^k\omega^2(X_k)=c_{ij}^ke^{a_k}X_k
\]
can also be computed as
\[
   \omega^2[X_i,X_j]=[\omega^2X_i,\omega^2X_j]=e^{a_i}e^{a_j}c_{ij}^kX_k,
\]
so that $c_{ij}^ke^{a_k}=c_{ij}^ke^{a_i}e^{a_j}$, and then $\forall t\in\eR$,
\[
   c_{ij}^ke^{ta_k}=c_{ij}^ke^{ta_i}e^{ta_j},
\]
which proves that $e^{tA}$ is an automorphism of $\lF$. By lemma~\ref{lem:autom_derr}, $A$ is thus a derivation of $\lF$. The semi-simplicity makes $\partial\lF=\ad\lF$, then $A\in\ad\lF$ and $e^{tA}\in\Int\lF$ because it clearly belongs to the identity component of $\Aut\lF$.

Now we can finish de proof by some computations. Remark that $\omega=e^{A/2}$ and $[e^{tA},\omega]=0$ because it can be seen as a common matrix commutator. Since $\omega^{-1}=\theta\sigma$, we have $\theta\omega^{-1}\theta=\sigma\theta$, or $\theta\omega^2\theta=\omega^2$ and
\begin{equation}\label{eq:eAth}
   e^{A}\theta=\theta e^{-A}.
\end{equation}
From this, one can deduce that $e^{tA}\theta=\theta e^{-tA}$. Indeed, as matricial identity, equation \eqref{eq:eAth} reads
\[
    (e^{A}\theta)_{ik}=(e^{A})_{ij}\theta_{jk}
                      =e^{a_i}\theta_{ik}
              =e^{-a_k}\theta_{ik}.
\]
Then for any $ik$ such that $\theta_{ik}\neq 0$, we find $e^{a_i}=e^{-a_k}$ and then also $e^{ta_i}=e^{-ta_k}$. Thus $(e^{tA}\theta)_{ik}=(e^{tA})_ij\theta_{jk}=e^{ta_i}\theta_{ik}=\theta_{ik}e^{-ta_k}=(\theta e^{-tA})_{ik}$. So we have
\begin{equation}
  e^{tA}\theta=\theta e^{-tA}.
\end{equation}
Now we consider $\varphi=e^{A/4}\in\Int\lF$ and $\theta_1=\varphi\theta\varphi^{-1}$. We find $\theta_1\sigma=e^{A/2}\omega^{-1}$ and $\sigma\theta^{-1}=e^{-A/2}\omega$. Since $\omega^2=A$, we have $e^{A/2}=e^{-A/2}\omega^2$ and thus $\theta_1\sigma=\sigma\theta_1$.

\end{proof}

\begin{corollary}
    Every real Lie algebra has a Cartan involution.
\end{corollary}

\begin{proof}
Let $\lF$ be a real Lie algebra and $\lG$ be his complexification: $\lG=\lF\heC$. Let $\lU_0$ be a compact real form of $\lG$ and $\tau$ the induced involution (the conjugation) on $\lG$. By the proposition~\ref{prop:conj_invol}, we know that $\tau$ is  a Cartan involution of $\lG\heR$. We also consider $\sigma$, the involution of $\lG$ with respect to the real form $\lF$. It is in particular an involution on the real Lie algebra $\lF$. Then one can find a $\varphi\in\Int\lG\heR$ such that $[\varphi\tau\varphi^{-1},\sigma]=0$ on $\lG\heR$. Let $\lU_1=\varphi\lU_0$ and $X\in\lU_1$. We can write $X=\varphi Y$ for a certain $Y\in\lU_0$. Then
\[
   \varphi\tau\varphi^{-1} X=\varphi\tau Y=\varphi Y=X,
\]
so that $\varphi\tau\varphi^{-1}=id|_{\lU_1}$. Note that $\lU_1$ is also a real compact form of $\lG$ because the Killing form is not affected by $\varphi$. Let $\tau_1$ be the involution of $\lG$ induced by $\lU_1$. We have
\[
   \tau_1|_{\lU_1}=\varphi\tau\varphi^{-1}_{\lU_1}=\id|_{\lU_1}.
\]
Since $\varphi$ is $\eC$-linear, we have in fact $\tau_1=\varphi\tau\varphi^{-1}$. Now we forget $\lU_0$ and we consider the compact real form $\lU_1$ with his involution $\tau_1$ of $\lG$ which satisfy $[\tau_1,\sigma]=0$ on $\lG\heR$ This relation holds also on $i\lG\heR$, then
\[
   [\tau_1,\sigma]=0
\]
on $\lG=\lF\heC$. Let $X\in\lF$, i.e. $\sigma X=X$; it automatically fulfils
\[
  \sigma\tau_1 X=\tau_1\sigma X=\tau_1 X,
\]
so that $\tau_1$ restrains to an involution on $\lF$ (because $\tau_1\lF\subset\lF$). Let $\theta=\tau_1|_{\lF}$. For $X$, $Y\in\lF$, we have
\begin{equation}
B_{\theta}(X,Y)=-B_{\lF}(X, \theta Y)
             =-B_{\lF}(X,\tau Y)
         =\frac{1}{2}(B_{\lG\heR})_{\tau_1}(X,Y),
\end{equation}
which shows that $\theta$ is a Cartan involution. The half factor on the last line comes from the fact that $\lG\heR=(\lF\heC)\heR=\lF\oplus i\lF$.

\end{proof}

\subsection{Cartan decomposition}
%-------------------------------

Examples of Cartan and Iwasawa decomposition are given in sections~\ref{SecToolSL},~\ref{SubSecIwaSOunn},\ref{subsecIwasawa_un},~\ref{SecSympleGp} and~\ref{SecIwasldeuxC}. An example of how it works to prove isomorphism of Lie algebras is provided in subsection~\ref{sssIsomsoslplussl}.

Let $\lF$ be a real semisimple Lie algebra. A vector space decomposition $\lF=\lK\oplus\lP$ is a \defe{Cartan decomposition}{Cartan!decomposition} if the Killing form is negative definite on $\lK$ and positive definite on $\lP$ and the following commutators hold:
\begin{equation}\label{eq:comm_Cartan}
   [\lK,\lK]\subseteq\lK,\quad[\lK,\lP]\subseteq\lP,\quad[\lP,\lP]\subseteq\lK.
\end{equation}
If $X\in\lK$ and $Y\in\lP$, we have $(\ad X\circ\ad Y)\lK\subseteq\lP$ and $(\ad X\circ\ad Y)\lP\subseteq\lK$, therefore $B_{\lF}(X,Y)=0$.

Let $\dpt{\theta}{\lF}{\lF}$ be a Cartan involution, $\lK$ its $+1$ eigenspace and $\lP$ his $-1$ one. It is easy to see that the relations \eqref{eq:comm_Cartan} are satisfied for the decomposition  $\lF=\lK\oplus\lP$. For example, for $X,X'\in\lK$, using the fact that $\theta$ is an automorphism,
\[
   [X,X']=[\theta X,\theta X']=\theta[X,X'],
\]
which proves that $[\lK,\lK]\subseteq\lK$. Since $\theta$ is a Cartan involution, $B_{\theta}$ is positive definite. For $X\in\lK$,
\[
  B(X,X)=B(X,\theta X)=-B_{\theta}(X,X)
\]
proves that $B$ is negative definite on $\lK$; in the same way we find that $B$ is also positive definite on $\lP$. Then the Cartan involution gives rise to a Cartan decomposition. We are going to prove that any Cartan decomposition defines a Cartan involution.

Let us now do the converse. Let $\lF=\lK\oplus\lP$ be a Cartan decomposition of the real semisimple Lie algebra $\lF$. We define $\theta=\id|_{\lK}\oplus(-\id)|_{\lP}$. If $X,X'\in\lK$, the definition of a Cartan algebra makes $[X,X']\in\lK$ and so
\[
  \theta[X,X']=[X,X']=[\theta X,\theta X'],
\]
and so on, we prove that $\theta$ is an automorphism of $\mF$. It remains to prove that $B_{\theta}$ is positive definite. If $X\in\lK$,
\[
   B_{\theta}(X,X)=-B(X,\theta X)=-B(X,X).
\]
Then $B_{\theta}$ is positive definite on $\lK$ because on this space, $B$ is negative definite by definition of a Cartan involution. The same trick shows that $B_{\theta}$ is also positive definite on $\lP$. We had seen that $\lP$ and $\lK$ where $B_{\theta}$-orthogonal spaces. Thus $B_{\theta}$ is positive definite and $\theta$ is a Cartan involution.

Let $\lF=\lK\oplus\lP$ be a Cartan decomposition. Then it is quite easy to see that $\lK\oplus i\lP$ is a compact real form of $\lG=(\lFeC)$.

\begin{proposition}
Let $\lL$ and $\lQ$ be the $+1$ and $-1$ eigenspaces of an involution $\sigma$. Then $\sigma$ is a Cartan involution if and only if $\lL\oplus i\lQ$ is  a compact real form of $\lFeC$.
\end{proposition}

\begin{proof}
First remark that $\lL\oplus i\lQ$ is always a real form of $\lFeC$. The direct sense is yet done. Then we suppose that $B_{\lFeC}$ is negative definite on $\lL\oplus i\lQ$ and we have to show that $\lL\oplus\lQ$ is a Cartan decomposition of $\lF$. The condition about the brackets on $\lL$ and $\lQ$ is clear from their definitions. If $X\in\lL$, $B(X,X)<0$ because $B$ is negative definite on $\lL$. If $Y\in\lQ$, $B(Y,Y)=-B(iY,iY)>0$ because $B$ is negative definite on $i\lQ$.
\end{proof}

\section{Root spaces in the real case}
%----------------------------------------

Let $\lF$ be a real semisimple Lie algebra with a Cartan involution $\theta$ and the corresponding Cartan decomposition $\lF=\lK\oplus\lP$. We consider $B$, a ``Killing like''{} form, i.e. $B$ is a symmetric nondegenerate invariant bilinear form on $\lF$ such that $B(X,Y)=B(\theta X,\theta Y)$ and $B_{\theta}:=-B(X,\theta X)$ is positive definite. Then $B$ is negative definite on the compact real form $\lK\oplus i\lP$. Indeed if $Y\in\lP$,
\begin{equation}
  B(iY,iY)=-B(\theta Y,\theta Y)
          =B(Y,\theta Y)
      =-B_{\theta}(Y,Y)<0.
\end{equation}
The case with $X\in\lK$ is similar. It is easy to see that $B_{\theta}$ is in fact a scalar product on $\lF$, so that we can define the orthogonality and the adjoint from $B_{\theta}$. If $\dpt{A}{\lF}{\lF}$ is an operator on $\lF$, his adjoint is the operator $A^*$ given by the formula
\[
   B_{\theta}(A X,Y)=B_{\theta}(X,A^*Y)
\]
for all $X$, $Y\in\lF$.

\begin{proposition}
With this definition, when $X\in\lF$, the adjoint operator of $\ad X$ is given by means of the Cartan involution:
\[
(\ad X)^*= \ad(\theta X).
\]
\end{proposition}

\begin{proof}
This is a simple computation
\begin{equation}
B_{\theta}\big(  (\ad\theta X)Y,Z \big)=-B\big(  Y,[\theta X,\theta Y]  \big)
                                     =-B_{\theta}(Y,[X,Z])
                     =-B_{\theta}\big( (\ad X)^*Y,Z \big).
\end{equation}
\end{proof}

Let $\lA$ be a maximal abelian subalgebra of $\lP$ (the existence comes from the finiteness of the dimensions). If $H\in\lA$, the operator $\ad H$ is self-adjoint because
\begin{equation}
(\ad H)^*X=(-\ad\theta H)X
          =[H,X]
      =(\ad H)X,
\end{equation}
where we used the fact that $H\in\lP$.  For $\lambda\in\lA^*$, we define the space
\begin{equation}
  \lF_{\lambda}=\{ X\in\lF\tq\forall H\in\lA,\, (\ad H)X=\lambda(H)X\}.
\end{equation}
If $\lF_{\lambda}\neq 0$ and $\lambda\neq 0$, we say that $\lambda$ is a \defe{restricted root}{restricted root (real case)}\index{root!restricted (real case)} of $\lF$. We denote by $\Sigma$ the set of restricted roots of $\lF$. We may sometimes write $\Sigma_{\lF}$ if the Lie algebra is ambiguous.

The main properties of the real root spaces are given in the following proposition.

\begin{proposition}     \label{PropPropRacincesReelles}
The set $\Sigma$ of the restricted roots of a real semisimple Lie algebra $\lF$ has the following properties:
\label{prop:enuc}
\begin{enumerate}
\item\label{enuci} $\lF=\lF_0\bigoplus_{\lambda\in\Sigma}\lF_{\lambda}$,
\item\label{enucii} $[\lF_{\lambda},\lF_{\mu}]\subseteq\lF_{\lambda+\mu}$,
\item\label{enuciii} $\theta\lF_{\lambda}=\lF_{-\lambda}$,
\item\label{enuciv} $\lambda\in\Sigma$ implies $-\lambda\in\Sigma$,
\item\label{enucv} $\lF_0=\lA\oplus\lM$ where $\lM=\mZ_{\lK}(\lA)$ and $\lA\perp\lM$.
\end{enumerate}
\end{proposition}

\begin{proof}
Proof of~\ref{enuci}. The operators $\ad H$ with $H\in\lA$ form an abelian algebra of self-adjoint operators, then they are simultaneously diagonalisable. Let $\{X_i\}$ be a basis which realize this diagonalisation, and $\lF_i=\Span X_i$, so that $\lF=\oplus_i\lF_i$. We have $(\ad H)\lF_i=\lF_i$ and then $(\ad H)X_i=\lambda_i(H)X_i$ for a certain $\lambda_i\in\lA^*$. This shows that $\lF_i\subseteq\lF_{\lambda_i}$.\quext{pourquoi Ã§a n'implique pas que $\dim\lF_{\lambda_i}=1$? RÃ©ponse par Philippe: tu as oubliÃ© les valeurs propres nulles  dans ta base ce qui doit entrainer quelques modifs dans ton texte(par  ex.  $adH f_i = f_i$ pas toujours ) }

Proof of~\ref{enucii}. Let $H\in\lA$, $X\in\lF_{\lambda}$ and $Y\in\lF_{\mu}$. We have
\begin{equation}
   (\ad H)[X,Y]=[[H,X],Y]+[X,[H,Y]]
               =\big(  \lambda(H)+\mu(H) \big) [X,Y].
\end{equation}

Proof of~\ref{enuciii}. Using the fact that $\theta H=-H$ because $H\in\lP$,
\begin{equation}
  (\ad H)\theta X=\theta[\theta H,X]
                 =-\theta\lambda(H)X
         =-\lambda(H)(\theta X).
\end{equation}

Proof of~\ref{enuciv}. It is a consequence of~\ref{enuciii} because if $\lF_{\lambda}\neq 0$, then $\theta\lF_{_{\lambda}}\neq 0$.

Proof of~\ref{enucv}. By~\ref{enuciii}, $\theta\lF_0=\lF_0$, then $\lF_0=(\lK\cap\lF_0)\oplus(\lP\cap\lF_0)$. If $X\in\lF_0$, then it commutes with all the elements of $\lA$ and by the maximality property of $\lA$, provided that $X\in\lP$, it also must belongs to $\lA$. This fact makes $\lA=\lP\cap\lF_0$. Now,
\[
  \lM=\mZ_{\lK}(\lA)=\{X\in\lK\tq [X,\lA]=0\}=\lK\cap\lF_0.
\]
All this gives $\lF_0=\mZ_{\lK}(\lA)\oplus\lA$.
\end{proof}

We choose a positivity notion on $\lA^*$, we consider $\Sigma^+$, the set of restricted positive roots and we define\nomenclature{$\lN$}{Restricted roots}
\[
  \lN=\bigoplus_{\lambda\in\Sigma^+}\lF_{\lambda}.
\]

From finiteness of the dimension, there are only a finitely many forms $\lambda\in\lA^*$ such that $\lF_{\lambda}\neq 0$. Then, taking, more and more commutators in $\lN$, the formula $[\lF_{\lambda},\lF_{\mu}]\subseteq\lF_{\lambda+\mu}$ shows that the result finish to fall into a $\lF_{\mu}=0$. On the other hand, since $\lA\subset\lF_0$, we have $[\lA,\lN]=\lN$. If $a_1,a_2\in\lA$ and $n_1,n_2\in\lN$,
\begin{equation}
   [a_1+n_1,a_2+n_2]=\underbrace{[a_1,a_2]}_{=0}+\underbrace{[a_1,n_2]}_{\in\lN}
                      \quad+\underbrace{[n_1,a_2]}_{\in\lN}+\underbrace{[n_1,n_2]}_{\in\lN},
\end{equation}
then $[\lA\oplus\lN,\lA\oplus\lN]=\lN$. This proves the three following important properties:

\begin{enumerate}
\item $\lN$ is nilpotent.
\item $\lA$ is abelian.
\item $\lA\oplus\lN$ is a solvable Lie subalgebra of $\lF$.
\end{enumerate}

\subsection{Iwasawa decomposition}
%----------------------------------

\begin{theorem}
Let $\lF$ be a real semisimple Lie algebra and $\lK$, $\lA$, $\lN$ as before. Then we have the following direct sum:
\begin{equation}
   \lF=\lK\oplus\lA\oplus\lN.
\end{equation}
\end{theorem}

This is the \defe{Iwasawa decomposition}{Iwasawa!decomposition}\index{decomposition!Iwasawa} for the real semisimple Lie algebra $\lF$.

\begin{proof}
We yet know the direct sum $\lF=\lF_0\bigoplus_{\lambda\in\Sigma}\lF_{\lambda}$. Roughly speaking, in $\lN$ we have only vectors of $\Sigma^+$, in $\theta\lN$, only of $\Sigma^-$ and in $\lA$, only in ``zero''. Then the sum $\lA\oplus\lN\oplus\theta\lN$ is direct.

Now we prove that the sum $\lK+\lA+\lN$ is also direct. It is clear that $\lA\cap\lN=0$ because $\lA\subseteq\lF_0$. Let $X\in\lK\cap(\lA\oplus\lN)$. Then $\theta X=X$. But $\theta X\in\lA\oplus\theta\lN$. Thus $X\in\lA\oplus\lN\cap\lA\oplus\lN$ which implies $X\in\lA$. All this makes $X\in\lP\oplus\lK$ and $X=0$.

Now we prove that $\lK\oplus\lA\oplus\lN=\lF$. An arbitrary $X\in\lF$ can be written as
\[
   X=H+X_0+\sum_{\lambda\in\Sigma}X_{\lambda}
\]
where $H\in\lA$, $X_0\in\lM$ and $X_{\lambda}\in\lF_{\lambda}$. Now there are just some manipulations\ldots
\begin{equation}
  \sum_{\lambda\in\Sigma}X_{\lambda}=\sum_{\lambda\in\Sigma^+}(X_{-\lambda}+X_{\lambda})
                                  =\sum_{\lambda\in\Sigma^+}(X_{-\lambda}+\theta X_{-\lambda})
                  +\sum_{\lambda\in\Sigma^+}(X_{\lambda}+\theta X_{-\lambda}),
\end{equation}
but $\theta(X_{-\lambda}+\theta X_{-\lambda})=X_{-\lambda}+\theta X_{-\lambda}$, then $X_{-\lambda}+X_{-\lambda}\in\lK$. Moreover, $X_{\lambda}, \theta X_{-\lambda}\in\lF_{\lambda}$, then $X_{\lambda}-\theta X_{-\lambda}\in\lF_{\lambda}\subseteq\lN$. Then
\begin{equation}
  X=X_0+\sum_{\lambda\in\Sigma^+}(X_{-\lambda}+\theta X_{-\lambda})+H+\sum_{\lambda\in\Sigma^+}(X_{\lambda}-\theta X_{-\lambda})
\end{equation}
where the two first term belong to $\lK$, $H\in\lA$ and the last term belongs to $\lN$.
\end{proof}

\begin{lemma}
There exists a basis $\{X_i\}$ of $\lF$ in which

\begin{enumerate}
\item\label{enudi} The matrices of $\ad\lK$ are symmetric,
\item\label{enudii} The matrices of $\ad\lA$ are diagonal and real,
\item\label{enudiii} The matrices of $\ad\lN$ are upper triangular with zeros on the diagonal.
\end{enumerate}
\end{lemma}

\begin{proof}
We have the orthogonal decomposition $\lF=\lF_0\bigoplus_{\lambda\in\Sigma}\lF_{\lambda}$ given by proposition~\ref{prop:enuc}. Let $\{X_i\}$ be an orthogonal basis of $\lF$ compatible with this decomposition and in such an order that $i<j$ implies $\lambda_i\geq\lambda_j$. From the orthogonality of the basis it follows that the matrix of $B_{\theta}$ is diagonal. Thus the adjoint is the transposition.

\ref{enudi} If $X\in\lK$, $(\ad X)^t=(\ad X)^*=-\ad\theta X=-\ad X$.

\ref{enudii} Each $X_i$ is a restricted root; then $(\ad H)X_i=\lambda_i(H)X_i$, then the diagonal of $\ad H$ is made of $\lambda_i(H)$ whose are real.

\ref{enudiii} If $Y_i\in\lF_{\lambda_i}$ with $\lambda_i\in\Sigma^+$, $(\ad Y_i)X_j$ has only components in $\lF_{\lambda_i+\lambda_j}$ with $\lambda_i+\lambda_j>\lambda_j$ because $\lambda_i\in\Sigma^+$.
\end{proof}


\begin{lemma}
Let $\lH$ be a subalgebra of the real semisimple Lie algebra $\lF$. Then $\lH$ is a Cartan subalgebra if and only if $\lHeC$ is Cartan in $\lFeC$.
\end{lemma}

\begin{proof}
\subdem{Direct sense} If $\lH$ is nilpotent in $\lF$, it is cleat that $\lHeC$ is nilpotent in $\lFeC$. We have to prove that $[x,\lHeC]\subseteq\lHeC$ implies $x\in\lHeC$. As set, $\lFeC=\mF\oplus i\lF$  (but not as vector space!), then we can write $x=a+ib$ with $a$, $b\in\lF$. The assumption makes that for any $h\in\lH$, there exists $h',h''\in\lH$ such that
\[
   [a+ib,h]=h+ih''.
\]
This equation can be decomposed in $\lF$-part and $i\lF$-part: for any $h\in\lH$, there exists a $h'\in\lH$ such that $[a,h]=h'$,  and for any $h\in\lH$, there exists a $h''\in\lH$ such that $[b,h]=h''$. Thus $a$, $b\in\lH$ because $\lH$ is Cartan in $\lF$.

\subdem{Inverse sense} The assumption is that $[x,\lHeC]\subset\lHeC$ implies $x\in\lHeC$. In particular consider a $x\in\lH$ such that $[x,\lH]\subset\lH$. Then $x\in\lHeC$ because $[x,\lHeC]\subset\lHeC$. But $\lHeC\cap\lF=\lH$.
\end{proof}

In the complex case, the Cartan subalgebras all have same dimensions because they are maximal abelian.

