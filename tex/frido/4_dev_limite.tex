% This is part of Analyse Starter CTU
% Copyright (c) 2014,2017
%   Laurent Claessens,Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Nombres de Bell}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Nombres de Bell\cite{KXjFWKA}]  \label{ThoYFAzwSg}
    Soit \( n\geq 1\) et \( B_n\) le nombre de partitions distinctes de l'ensemble \( \{ 1,\ldots, n \}\) avec la convention que \( B_0=0\). Alors
    \begin{enumerate}
        \item
            La série entière
            \begin{equation}    \label{EqYCMGBmP}
                \sum_{n=0}^{\infty}\frac{ B_n }{ n! }x^n
            \end{equation}
            a un rayon de convergence \( R>0\) et sa somme est donnée par
            \begin{equation}
                f(x)= e^{ e^{x}-1}
            \end{equation}
            pour tout \( x\in\mathopen] -R , R \mathclose[\).
        \item
            Pour tout \( k\in \eN\),
            \begin{equation}
                B_n=\frac{1}{ e }\sum_{k=0}^{\infty}\frac{ k^n }{ k! }.
            \end{equation}
            \item
                Le rayon de convergence de la série \eqref{EqYCMGBmP} est en réalité infini : \( R=\infty\).
    \end{enumerate}
\end{theorem}
\index{anneau!de séries formelles}
\index{dénombrement!partitions de \( \{ 1,\ldots, n \} \)}
\index{série!numérique}
\index{série!entière}
\index{limite!inversion}

\begin{proof}
    \begin{enumerate}
        \item
            Soit \( n\geq 1\) et \( 0\leq k\leq n\). Nous notons \( E_k\) l'ensemble des partitions de \( \{ 1,\ldots, n+1 \}\) pour lesquelles le «paquet» contenant \( n+1\) soit de cardinal \( k+1\). Calculons le cardinal de \( E_k\).

            Pour construire un élément de \( E_k\), il faut d'abord prendre le nombre \( n+1\) et lui adjoindre \( k\) éléments choisis dans \( \{ 1,\ldots, n \}\), ce qui donne \( n\choose k\) possibilités. Ensuite il faut trouver une partition des \( (n+1)-(k+1)=n-k\) éléments restants, ce qui fait \( B_{n-k}\) possibilités. Donc
            \begin{equation}
                \Card(E_k)={n\choose k}B_{n-k}.
            \end{equation}
            L'intérêt des ensembles \( E_k\) est que \( \{ E_0,\ldots, E_n \}\) est une partition de l'ensemble des partitions de \( \{ 1,\ldots, n+1 \}\), c'est à dire que \( B_{n+1}=\sum_{k=0}^n\Card(E_k)\), ce qui va nous donner une relation de récurrence pour les \( B_n\) :
\begin{equation}
                    B_{n+1}=\sum_{k=0}^n\Card(E_k)
                   =\sum_{k=0}^n{n\choose k}B_{n-k}
                    =\sum_{l=0}^n{n\choose n-l}B_l 
                    =\sum_{l=0}^n{n\choose l}B_l.
\end{equation}
où nous avons utilisé un petit changement de variables \( l=n-k\). Afin d'étudier la convergence de la série \eqref{EqYCMGBmP}, nous allons montrer par récurrence que pour tout \( n\), \( B_n<n!\). D'abord pour \( n=0\) c'est bon : \( B_1=1\) parce que la seule partition de \( \{ 1 \}\) est \( \{ 1 \}\). Supposons que l'inégalité soit vraie pour une certaine valeur \( k\), et montrons qu'elle est vraie pour la valeur \( k+1\) :
\begin{equation}
                    B_{k+1}=\sum_{l=0}^n{n\choose k}B_k
                   \leq \sum_{l=0}^n{n\choose k}k!
                    =k!\sum_{l=0}^k\underbrace{\frac{1}{ (n-k)! }}_{\leq 1}
                    \leq n!(n+1)
                    =(n+1)!
\end{equation}
            où nous avons utilisé la formule \( {n\choose k}=\frac{ n! }{ k!(n-k)! }\).

            Donc pour tout \( x\in \eR\) nous avons
            \begin{equation}
                0\leq \frac{ B_n }{ n! }| x^n |\leq | x |^n,
            \end{equation}
            et donc la série a un rayon de convergence au moins aussi grand que celui de la série géométrique, c'est à dire que \( 1\). Donc \( R\geq 1\). Nous nommons \( R\) ce rayon de convergence.

        \item

            Soit \( x\in\mathopen] -R , R \mathclose[\). Pour une telle valeur de \( x\) à l'intérieur du disque de convergence, la proposition \ref{ProptzOIuG} nous permet de dériver terme à terme la série\footnote{C'est ici qu'on utilise la convention \( B_0=0\) et ça aura une influence sur le choix de la constante \( K\) plus bas.}
                \begin{equation}
                    f(x)=\sum_{k=0}^{\infty}\frac{ B_k }{ k! }x^k=1+\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ (k+1)! }x^{k+1},
                \end{equation}
                pour obtenir
                \begin{equation}
                    f'(x)=\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ (k+1) }(k+1)x^k=\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ k! }x^k=\sum_{k=0}^{\infty}\left( \sum_{l=0}^k{k\choose l}B_l \right)\frac{ x^k }{ k! }=\sum_{k=0}^{\infty}\left( \sum_{l=0}^k\frac{ B_l }{ l!(l-k)! } \right)x^k.
                \end{equation}
                En cette expression, nous reconnaissons un produit de Cauchy (proposition \ref{ThokPTXYC}) avec \( a_l=\frac{ B_l }{ l! }\) et \( b_n=\frac{ 1 }{ n! }\). Vu que ce sont deux séries ayant un rayon de convergence plus grand que zéro, le produit a encore un rayon de convergence plus grand que zéro et nous pouvons prendre le produit des séries :
                \begin{equation}
                    f'(x)=\left( \sum_{l=0}^{\infty}\frac{ B_l }{ l! }x^l \right)\left( \sum_{k=0}^{\infty}\frac{1}{ k! }x^k \right)=f(x) e^{x}.
                \end{equation}
            Étudions l'équation différentielle \( y'=ye^x\). D'abord par un argument en lacet de chaussure\footnote{Genre ce qui est fait pour prouver \ref{ThoRWOZooYJOGgR}\ref{ItemYTLTooSnfhOu}.}, une solution est de classe \(  C^{\infty}\). Ensuite si une solution est non nulle, elle est de signe constant. En effet si \( y(x_0)<0\) et \( y(x_1)=0\) (on choisit \( x_1\) minimum pour cette propriété parmi les nombres plus grands que \( x_0\)) alors il existe\footnote{Théorème de Rolle \ref{ThoRolle}.} un \( t\in\mathopen] x_0 , x_1 \mathclose[\) tel que \( y'(t)>0\), ce qui donnerait \( y(t)>0\), ce qui contredirait la minimalité de \( x_1\).

                Nous prétendons\footnote{Ou alors on utilise le théorème \ref{ThoNYEXqxO} avec \( M(x)=e^x\) dans les cas \( n=1\) et \( I=\mathopen] -R , R \mathclose[\).} que cette équation différentielle a un espace de solutions de dimension \( 1\). En effet, si \( y'=ye^x\) et \( g'=ge^x\) alors en posant \( \varphi=y/g\) nous obtenons tout de suite \( \varphi'=0\), ce qui signifie que \( \varphi\) est constante, ou encore que \( y\) et \( g\) sont multiples l'un de l'autre.

                 Si nous en trouvons une non nulle par n'importe quel moyen, c'est bon. Une solution étant dérivable est continue, donc l'équation \( f'=f e^{x}\) nous indique que \( f'\) est continue. Une solution non nulle va automatiquement accepter un petit voisinage sur lequel la manipulation suivante a un sens :
                    \begin{equation}
                        \frac{ f'(x) }{ f(x) }= e^{x},
                    \end{equation}
                    donc \( \ln\big( | f(x) | \big)= e^{x}+C\) et \( f(x)=K e^{ e^{x}}\) pour une certaine constante. Il est vite vérifié que cette fonction est une solution de l'équation différentielle \( y'(x)=y(x) e^{x}\) et par unicité, toutes les solutions sont de cette forme. Autrement dit, l'espace des solution est l'espace vectoriel \( \Span\{ x\mapsto e^{e^x} \}\). Étant donné que \( f(0)=0\), nous devons choisir \( K=\frac{1}{ e }\) et donc 
                    \begin{equation}
                        f(x)=\frac{1}{ e } e^{e^x}= e^{e^x-1}.
                    \end{equation}

                \item

                    Nous commençons par écrire la fonction \( f\) comme une série de puissance. La partie simple du calcul : pour \( x\in \mathopen] -R , R \mathclose[\), nous avons
                        \begin{equation}    \label{EqODjgjDN}
                        e^{e^x}=\sum_{k=0}^{\infty}\frac{ (e^x)^k }{ k! }=\sum_{k=0}^{\infty}\frac{1}{ k! }\sum_{l=0}^{\infty}\frac{ (kx)^l }{ l! }=\sum_{k=0}^{\infty}\sum_{l=0}^{\infty}\frac{k^l}{k! }\frac{ x^l }{ l! }.
                    \end{equation}
                    Notons que cela n'est pas une série de puissance en \( x\) parce qu'il y a la double somme. Nous allons inverser les sommes au moyen du théorème de Fubini sous la forme du corollaire \ref{CorTKZKwP}. Pour cela nous considérons la fonction
                    \begin{equation}
                        \begin{aligned}
                            a\colon \eN\times \eN&\to \eR \\
                            (k,l)&\mapsto \frac{ (kx)^l }{ k!l! } 
                        \end{aligned}
                    \end{equation}
                    et nous mettons la mesure de comptage\footnote{Nous passons outre les avertissements et menaces de Arnaud Girand.} sur \( \eN\) et \( \eN^2\). Nous commençons donc à vérifier l'intégrabilité variable par variable de \( | a |\) :
                    \begin{subequations}    \label{SubEqsFHsBfhk}
                        \begin{align}
                            \int_{\eN}\left( \int_{\eN}| a(k,l) |dm(l) \right)dm(k)&=\sum_{k=0}^{\infty}\frac{1}{ k! }\frac{ (k| x |)^l }{ l! }\\
                            &=\sum_{k=0}^{\infty}\frac{1}{ k! } e^{k| x |}.
                        \end{align}
                    \end{subequations}
                    Nous devons montrer que cette dernière somme va bien. Pour cela nous posons \( u_k=\frac{ e^{k| x |} }{ k! }\) et nous remarquons que \( \frac{ u_{k+1} }{ u_k }\to 0\). Donc la double intégrale \eqref{SubEqsFHsBfhk} converge, ergo \( a\in L^1(\eN\times \eN)\), ce qui nous permet d'utiliser le théorème de Fubini \ref{ThoFubinioYLtPI} pour inverser les \sout{sommes} \sout{intégrales} sommes dans l'équation \eqref{EqODjgjDN} :
                    \begin{equation}
                        \frac{1}{ e }e^{e^x}=\frac{1}{ e }\sum_{k=0}^{\infty}\sum_{l=0}^{\infty}\frac{1}{ k! }\frac{1}{ l! }(kx)^l=\sum_{l=0}\frac{1}{ e }\frac{1}{ l! }\left( \sum_{k=0}^{\infty}\frac{ k^l }{ k! } \right)x^l.
                    \end{equation}
                    Cela est un développement en série entière pour la fonction \( \frac{1}{ e } e^{e^x}\), dont nous savions déjà le développement \eqref{EqYCMGBmP}; par unicité du développement nous pouvons identifier les coefficients :
                    \begin{equation}
                        B_l=\frac{1}{ e }\sum_{k=0}^{\infty}\frac{ k^l }{ k! }.
                    \end{equation}
                    
                \item

                    Le développement \eqref{EqODjgjDN} étant en réalité valable pour tout \( x\) et tous les calculs subséquents l'étant aussi, le développement
                    \begin{equation}
                        e^{e^x-1}=\sum_{n=0}^{\infty}\frac{ B_n }{ n! }x^n
                    \end{equation}
                    est en fait valable pour tout \( x\), ce qui donne à la série entière un rayon de convergence infini.
    \end{enumerate}
\end{proof}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Développement asymptotique, théorème de Taylor}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{AppSecTaylorR}

\begin{theorem}[Théorème de Taylor\cite{TrenchRealAnalisys,ooCNZAooJEcgHZ}]		\label{ThoTaylor}
Soit $I\subset$ un intervalle non vide et non réduit à un point de $\eR$ ainsi que $a\in I$. Soit une fonction $f\colon I\to \eR$ telle que $f^{(n)}(a)$ existe. Alors il existe une fonction $\alpha$ définie sur $I$ et à valeurs dans $\eR$ vérifiant les deux conditions suivantes :
\begin{subequations}		\label{SubEqsDevTauil}
	\begin{align}
		f(x)&= \sum_{k=0}^n\frac{ f^{(k)}(a) }{ k! }(x-a)^k +\alpha(x)(x-a)^{n},		\label{subeqfTepseqb}
		\lim_{t\to a}\alpha(t)&=0
	\end{align}
\end{subequations}
pour tout \( x\in I\). Ici $f^{(k)}$ dénote la $k$-ième dérivée de $f$ (en particulier, $f^{(0)}=f$, $f^{(1)}=f'$).\nomenclature{$f^{(n)}$}{La $n$-ième dérivée de la fonction $f$}
\end{theorem}

Nous insistons sur le fait que la formule \eqref{subeqfTepseqb} est une égalité, et non une approximation. Ce qui serait une approximation serait de récrire la formule dans le terme contenant $\alpha$.

Le polynôme $T^a_{f,n}$ est le \defe{polynôme de Taylor}{Taylor} de $f$ au point $a$ à l'ordre $n$. 

Les conditions \eqref{SubEqsDevTauil} sont souvent aussi énoncées sous la forme qu'il existe une fonction \( \alpha\) telle que
\begin{subequations}    \label{SUBEQooPYABooKpDgdu}
    \begin{numcases}{}
        \lim_{t\to 0} \frac{ \alpha(t) }{ t^n }=0\\
        f(a+h)=f(a)+hf'(a)+\frac{ h^2 }{2}f''(a)+\cdots+ \frac{ h^n }{ n! }f^{(n)}(a)+\alpha(h).
    \end{numcases}
\end{subequations}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonctions «petit o» }
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons formaliser l'idée d'une fonction qui tend vers zéro \og plus vite\fg{} qu'une autre. Nous disons que $f\in o\big(\varphi(x)\big)$ si
\begin{equation}
    \lim_{x\to 0} \frac{ f(x) }{ \varphi(x) }=0.
\end{equation}
En particulier, nous disons que $f\in o(x)$ lorsque $\lim_{x\to 0} f(x)/x=0$.

\begin{remark}
    À titre personnel, l'auteur de ces lignes déconseille d'utiliser cette notation qui est un peu casse-figure pour qui ne la maîtrise pas bien.
\end{remark}

En termes de notations, nous définissons l'ensemble $o(x)$\nomenclature{$o(x)$}{fonction tendant rapidement vers zéro} l'ensemble des fonctions $f$ telles que
\begin{equation}
	\lim_{x\to 0} \frac{ f(x) }{ x }=0.
\end{equation}
Plus généralement si $g$ est une fonction telle que $\lim_{x\to 0} g(x)=0$, nous disons $f\in o(g)$ si
\begin{equation}
	\lim_{x\to 0} \frac{ f(x) }{ g(x) }=0.
\end{equation}
De façon intuitive, l'ensemble $o(g)$ est l'ensemble des fonctions qui tendent vers zéro «plus vite» que $g$.

Nous pouvons donner un énoncé alternatif au théorème \ref{ThoTaylor} en définissant $h(x)=\epsilon(x+a)x^n$. Cette fonction est définie exprès pour avoir
\begin{equation}
	h(x-a)=\epsilon(x)(x-a)^n,
\end{equation}
et donc
\begin{equation}
	\lim_{x\to 0} \frac{ h(x) }{ x^n }=\lim_{x\to 0} \epsilon(x-a)=\lim_{x\to a}\epsilon(x)=0. 
\end{equation}
Donc $h\in o(x^n)$.

Le théorème dit donc qu'il existe une fonction $\alpha\in o(x^n)$ telle que
\begin{equation}
	f(x)=T^a_{f,n}(x)+\alpha(x-a).
\end{equation}
pour tout $x\in I$. 

\begin{example}
    L'exemple \ref{EXooXLYJooKVqhTE} du développement du cosinus sera traité quand les fonctions trigonométriques seront définies.
\end{example}

\begin{proposition}[Ordre deux sur \( \eR^n\)\cite{MonCerveau}]
    Soit un ouvert \( \Omega\) de \( \eR^n\) et \( a\in \Omega\) ainsi qu'une fonction \( f\colon \Omega\to \eR\) de classe \( C^2\). Alors il existe une fonction \( \alpha\colon \eR^n\to \eR\) telle que
    \begin{subequations}
        \begin{numcases}{}
            f(a+h)=f(a)+df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\| h \|^2\alpha(h)\\
            \lim_{h\to 0} \alpha(h)=0.
        \end{numcases}
    \end{subequations}
    Ici, la notation \( (d^2f)_a(h,h)\) réfère à ce qui est expliqué en \ref{NORMooZAOEooGqjpLH}.
\end{proposition}

\begin{proof}
    Dans la suite nous considérons \( t\) et \( h\) tels que toutes les expressions suivantes aient un sens, c'est à dire que tous les trucs comme \( a+th\) restent dans \( \Omega\). Pour \( h\in \eR^n\) nous nommons \( e_h\) le vecteur unitaire dans la direction de \( h\), c'est à dire \( e_h=h/\| h \|\) et nous posons
    \begin{equation}
        k_h(t)=f(a+te_h).
    \end{equation}
    et nous lui appliquons Taylor \ref{ThoTaylor} à l'ordre deux : il existe une fonction \( \beta_h\) telle que
    \begin{equation}        \label{EQooETDFooAmiRcV}
        k_h(x)=k_h(0)+xk_h'(0)+\frac{ x^2 }{2}k''_h(0)+x^2\beta_h(x).
    \end{equation}
    avec \( \lim_{x\to 0} \beta_h(x)=0\).

    En ce qui concerne les dérivées de \( k_h\) nous avons 
    \begin{equation}
        k'_h(0)=df_a(e_h)
    \end{equation}
    et
    \begin{equation}
        k_h''(0)=(d^2f)_{a}(e_h,e_h).
    \end{equation}
    Il est maintenant temps d'écrire \( f(a+h)=k(\| h \|)\) et de substituer les dérivées de \( k\) par les différentielles de \( f\) dans \eqref{EQooETDFooAmiRcV} :
    \begin{equation}        \label{EQooUSUGooYPscxV}
            f(a+h)=k(\| h \|)=f(a)+df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\| h^2 \|\beta_{h}(\| h \|).
    \end{equation}
    Il reste à voir que la fonction \( \alpha\colon h\mapsto \beta_h(\| h \|)\) tend vers zéro pour \( h\to 0\). En prenant la limite \( h\to 0\) dans \eqref{EQooUSUGooYPscxV}, il est manifeste que la limite du membre de gauche existe et vaut \( f(a)\). Donc la limite du membre de droite doit exister et valoir également \( f(a)\). Nous en déduisons que la limite de
    \begin{equation}
        df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\| h \|^2\beta_h(\| h \|)
    \end{equation}
    existe et vaut zéro. La limite des deux premiers termes existe et vaut zéro, donc la limite du troisième existe et vaut zéro :
    \begin{equation}
        \lim_{h\to 0} \| h \|^2\beta_h(\| h \|)=0.
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Autres formulations}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}		\label{ExempleUtlDev}
	Une des façons les plus courantes d'utiliser les formules \eqref{SubEqsDevTauil} est de développer $f(a+t)$ pour des petits $t$ en posant $x=a+t$ dans la formule :
	\begin{equation}	\label{EqDevfautouraeps}
		f(a+t)=f(a)+f'(a)t+f''(a)\frac{ t^2 }{ 2 }+\epsilon(a+t)t^2
	\end{equation}
	avec $\lim_{t\to 0} \epsilon(a+t)=0$. Ici, la fonction $T$ dont on parle dans le théorème est $T_{f,2}^a(a+t)=f(a)+f'(a)t+f''(a)\frac{ t^2 }{2}$.

	Lorsque $x$ et $y$ sont deux nombres «proches\footnote{par exemple dans une limite $(x,y)\to(h,h)$.}», nous pouvons développer $f(y)$ autour de $f(x)$ :
	\begin{equation}		\label{Eqfydevfx}
		f(y)=f(x)+f'(x)(y-x)+f''(x)\frac{ (y-x)^2 }{ 2 }+\epsilon(y-x)(y-x)^2,
	\end{equation}
	et donc écrire
	\begin{equation}
		f(x)-f(y)=-f'(x)(y-x)-f''(x)\frac{ (y-x)^2 }{ 2 }-\epsilon(y-x)(y-x)^2.
	\end{equation}
	De cette manière nous obtenons une formule qui ne contient plus que $y$ dans la différence $y-x$.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Formule et reste}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{PropDevTaylorPol}
    Soient $f\colon I\subset\eR\to \eR$ et $a\in\Int(I)$. Soit un entier $k\geq 1$. Si $f$ est $k$ fois dérivable en $a$, alors il existe un et un seul polynôme $P$ de degré $\leq k$ tel que
    \begin{equation}
        f(x)-P(x-a)\in o\big( | x-a |^k \big)
    \end{equation}
    lorsque $x\to a$, $x\neq a$. Ce polynôme  est donné par
    \begin{equation}
        P(h)=f(a)+f'(a)h+\frac{ f''(a) }{ 2! }h^2+\cdots+\frac{ f^{(k)}(a) }{ k! }h^k.
    \end{equation}
    Notons encore deux façons alternatives d'écrire le résultat. Si \( f\in C^k\) il existe une fonction \( \alpha\) telle que \( \lim_{t\to 0} \alpha(t)=0\) et
    \begin{equation}
        f(x)=\sum_{n=0}^k\frac{ f^{(n)}(a) }{ n! }(x-a)^n+(x-a)^n\alpha(x-a).
    \end{equation}
    Si \( f\in C^{k+1}\) alors
    \begin{equation}        \label{EquQtpoN}
        f(x)=\sum_{n=0}^k\frac{ f^{(n)}(a) }{ n! }(x-a)^n+(x-a)^{n+1}\xi(x-a)
    \end{equation}
    où \( \xi\) est une fonction telle que \( \xi(t)\) tend vers une constante lorsque \( t\to 0\).
\end{proposition}

La proposition suivant donne une intéressante façon de trouver le reste d'un développement de Taylor.
\begin{proposition}     \label{PropResteTaylorc}
Soient $I$, un intervalle dans $\eR$ et $f\colon I\to \eR$ une fonction de classe $C^k$ sur $I$ telle que $f^{(k+1)}$ existe sur $I$. Soient $a\in\Int(I)$ et $x\in I$. Alors il existe $c\in\mathopen] x , a \mathclose[$ tel que
\begin{equation}
    f(x)=\sum_{n=0}^k\frac{ f^{(n)}(a) }{ n! }(x-a)^n+\frac{ f^{(k+1)}(c) }{ (k+1)! }(x-a)^{k+1}.
\end{equation}
\end{proposition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Reste intégral}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[Formule de Taylor avec reste intégral\cite{VBYOJrU}]\label{PropAXaSClx}
    Soient \( X\) et \( Y\) des espaces normés et un ouvert \( \mO\subset X\). Si \( f\in C^m(\mO,Y)\) et si \( [p,x]\subset \mO\) alors
    \begin{equation}
        \begin{aligned}[]
            f(x)=f(p)&+\sum_{k=1}^{m-1}\frac{1}{ k! }(d^kf)_p (x-p)^k \\
            &+\frac{1}{ (m-1)! }\int_0^1(1-t)^{m-1}(d^mf)_{ p+t(x-p) }(x-p)^m \
        \end{aligned}
    \end{equation}
    où \( \omega_pu^k\) signifie \( \omega_p(u,\ldots, u)\) lorsque \( \omega\in \Omega^k\).
\end{proposition}
\index{formule!Taylor!reste intégral}
Comme expliqué dans l'exemple \ref{ExZHZYcNH}, toute ces applications de différentielles se réduisent à des termes de la forme
\begin{equation}
    f^{(k)}(p)(x-p)^k
\end{equation}
dans le cas d'une fonction \( \eR\to\eR\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Développement limité autour de zéro}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans cette sections nous supposons toujours que les fonctions sont définies sur un intervalle ouvert de $\eR$, $I$, contenant \( 0\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Généralités}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Soit \( f\colon I\to 0\) une fonction définie sur un ouvert \( I\) autour de zéro. Nous disons que \( f\) admet un \defe{développement limité}{développement!limité!en zéro} autour de \( 0\) à l'ordre \( n\) s'il existe une fonction \( \alpha\colon I\to \eR\) telle que
    \begin{subequations}
        \begin{numcases}{}
            f(x)=P_n(x)+x^n\alpha(x)\\
            \lim_{x\to 0} \alpha(x)=0
        \end{numcases}
    \end{subequations}
    où \( P(x)=a_0+a_1x+\cdots +a_nx^n\) est une polynôme de degré \( n\). Le polynôme \( P_n\) est appelé la \defe{partie régulière}{partie!régulière} du développement.
\end{definition}
La fonction \( \alpha\) est appelé le \defe{reste}{reste!d'un développement limité} du développement et sera parfois noté \( \alpha_f\). Lorsque \( P\) est la partie régulière d'un développement limité de \( f\) nous notons parfois \( f\sim P\).

\begin{proposition}[Troncature]
    Si \( f\) admet un développement limité d'ordre \( n\) alors il admet également un développement limité d'ordre \( n'\) pour tout \( n'<n\). Ce dernier s'obtient en tronquant le polynôme d'ordre \( n\) à l'ordre \( n'\).
\end{proposition}

\begin{proposition}[Unicité]
    Si \( f\) admet une développement limité alors ce dernier est unique : il existe un unique polynôme \( P_n\) d'ordre \( n\) et une unique fonction \( \alpha\) vérifiant simultanément les deux conditions
    \begin{subequations}
        \begin{numcases}{}
            f(x)=P_n(x)+x^n\alpha(x),\\
            \lim_{x\to 0} \alpha(x)=0.
        \end{numcases}
    \end{subequations}
\end{proposition}

\begin{example} \label{ExTHGooCBcnAy}
    En ce qui concerne les séries géométriques de raison \( x\) nous savons les formules
    \begin{equation}
        1+x+x^2+\cdots +x^n=\frac{ 1-x^{n+1} }{ 1-x }
    \end{equation}
    et
    \begin{equation}
        1+x+x^2+x^3+\cdots=\frac{ 1 }{ 1-x }
    \end{equation}
    pour tout \( x\in\mathopen] -\infty , 1 \mathclose[\). Comparant les deux, il est naturel d'essayer de prendre \( 1+x+x^2+\cdots +x^n\) comme développement limité de la fonction \( f(x)=\frac{1}{ 1-x }\). Pour voir si cela fonctionne, il faut vérifier si «le reste» est bien de la forme \( x^n\alpha(x)\) avec \( \lim_{x\to 0} \alpha(x)=0\).

    Le reste en question est donné par
    \begin{equation}
        \frac{1}{ 1-x }-1-x-x^2-\ldots-x^n=\frac{1}{ 1-x }-\frac{ 1-x^{n+1} }{ 1-x }=\frac{ x^{n+1} }{ 1-x }=x^n\frac{ x }{ 1-x }.
    \end{equation}
    En posant \( \alpha(x)=\frac{ x }{ 1-x }\) nous avons donc bien
    \begin{equation}
        f(x)=\frac{1}{ 1-x }=1+x+x^2+\cdots +x^n+x^n\frac{ x }{ 1-x }
    \end{equation}
    et \( \lim_{x\to 0} \frac{ x }{ 1-x }=0\). Cela est le développement limité de \( f\) à l'ordre \( n\) autour de \( 0\).
\end{example}

La formule des accroissements finis est un cas particulier de développement fini. Supposons que \( f\) soit dérivable en \( 0\). En effet nous pouvons facilement trouver la fonction \( \alpha\) qui convient. Sachant que \( f(0)+xf'(0)\) donne l'approximation affine de \( f\) autour de \( 0\), nous cherchons \( \alpha\) en écrivant
\begin{equation}
    f(x)=f(0)+xf'(0)+x\alpha(x).
\end{equation}
Cela nous pousse à définir
\begin{equation}    \label{EqDCFooKozKrt}
    \alpha(x)=\frac{ f(x)-f(0) }{ x }-f'(0).
\end{equation}
Notons que cette fonction n'est pas définie en \( x=0\), mais cela n'a pas d'importance : seule la limite \( \lim_{x\to 0} \alpha(x)\) nous intéresse. Par définition de la dérivée,
\begin{equation}
    \lim_{x\to 0} \alpha(x)=\lim_{x\to 0} \frac{ f(x)-f(0) }{ x }-f'(0)=0.
\end{equation}

En conclusion si \( f\) est dérivable, son développement limité à l'ordre \(  1\) est donné par
\begin{equation}
    f(x)=f(0)+xf'(0)+x\alpha(x)
\end{equation}
où \( \alpha(x)\) est donnée par la formule \eqref{EqDCFooKozKrt}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Formule de Taylor-Young}
%---------------------------------------------------------------------------------------------------------------------------

Plus généralement nous avons la proposition suivante qui donne le développement limité de toute fonction dérivable \( n\) fois.

\begin{proposition}[Formule de Taylor-Young]    \label{PropVDGooCexFwy}
    Soit \( f\) une fonction \( n\) fois dérivable sur un intervalle \( I\) contenant \( 0\). Alors il existe une fonction \( \alpha\colon I\to \eR\) telle que
    \begin{equation}        \label{EQooBKZDooTqYyIB}
        f(x)=f(0)+f'(0)x+\frac{ f''(0) }{ 2 }x^2+\frac{ f^{(3)}(0) }{ 3! }x^3+\cdots +\frac{ f^{(n)}(0) }{ n! }x^n+x^n\alpha(x)
    \end{equation}
    et
    \begin{equation}
        \lim_{x\to 0} \alpha(x)=0.
    \end{equation}
\end{proposition}

Cette proposition nous permet de trouver facilement des développements limités. Dans l'exemple \ref{ExTHGooCBcnAy} nous avons dû utiliser des astuces et des formules pour déterminer le développement limité de \( \frac{1}{ 1-x }\). Au contraire la formule \eqref{EQooBKZDooTqYyIB} nous permet de trouver le polynôme en calculant seulement de dérivées.

\begin{example}
    Utilisation de la formule \eqref{EQooBKZDooTqYyIB} pour déterminer le développement limité de la fonction
    \begin{equation}
        f(x)=\frac{1}{ 1-x }.
    \end{equation}
    Il faut calculer les dérivées successives de \( f\) :
    \begin{subequations}
        \begin{align}
            f(x)&=\frac{1}{ 1-x }\\
            f'(x)&=\frac{ 1 }{ (1-x)^2 }\\
            f''(x)&=\frac{ 2 }{ (1-x)^3 }
        \end{align}
    \end{subequations}
    Avec ces résultats, nous devinons que 
    \begin{equation}
        f^{(n)}(x)=\frac{ n! }{ (1-x)^{n+1} }.
    \end{equation}
    Pour en être sûr nous le prouvons par récurrence. La dérivée de \(\frac{ n! }{ (1-x)^{n+1} } \) est donnée par
    \begin{equation}
        \frac{ n!(n+1)(1-x)^n }{ (1-x)^{2n+2} }=\frac{(n+1)! }{ (1-x)^{n+2} }.
    \end{equation}
    Évaluées en \( x=0\), les dérivées successives de \( f\) sont \( f(0)=0\), \( f'(0)=1\), \( f''(0)=2\),\ldots,\( f^{(n)}(0)=n!\). Utilisant la formule \eqref{EQooBKZDooTqYyIB} nous avons
    \begin{equation}
        f(x)=1+x+x^2+\cdots +x^n+x^n\alpha(x),
    \end{equation}
    conformément à ce que nous avions déjà trouvé.
\end{example}
\begin{remark}
  Pour alléger la notation et ne pas écrire \(\ldots +x^n\alpha(x)\) nous pouvons aussi écrire
    \begin{equation}
         f(x)\sim 1+x+x^2+\cdots +x^n,
    \end{equation}
    mais il est interdit d'écrire
    \begin{equation}
         f(x)= 1+x+x^2+\cdots +x^n
    \end{equation}
    en mettant un signe d'égalité entre une fonction et son développement limité\footnote{Il faut cependant \^etre très prudents avec la notation abrégée. Elle pourrait nous faire oublier des informations importantes, voir les développements des fonction trigonométriques pour un exemple.}.
\end{remark}

Notons cependant que la proposition \ref{PropVDGooCexFwy} ne donne pas de moyen simple de trouver la fonction \( \alpha\). Si la fonction $f$ est très régulière dans l'intervalle $I$ on a le résultat suivant.

\begin{proposition}[Reste dans la forme de Lagrange]
    Si la fonction $f$ est dérivable $n+1$ fois dans $I$ alors il existe $\bar x$ dans l'intervalle \( \mathopen[ 0 , x \mathclose]\) tel que
  \begin{equation}
    f(x) = P_n(x) + \frac{1}{(n+1)!} f^{n+1}(\bar x) x^{n+1}.
  \end{equation}
\end{proposition}
Voici quelque développements limités à savoir. Ils sont calculables en utilisant la formule de Taylor-Young (proposition \ref{PropVDGooCexFwy}).
\begin{framed}
    \begin{subequations}  \label{SUBEQSooIFXBooIOkveI}
    \begin{align}
      e^x&=\sum_{k=0}^n\frac{ x^k }{ k! }+x^n\alpha(x)&\text{ordre } n\\
      \cos(x)&=\sum_{k=0}^p\frac{ (-1)^kx^{2k} }{ (2k)! }+x^{2p+1}\alpha(x)&\text{ordre } 2p+1    \label{subeqCBQooTZGxQpcos}\\
      \sin(x)&=\sum_{k=0}^p\frac{ (-1)^kx^{2k+1} }{ (2k+1)! }+x^{p+2}\alpha(x)&\text{ordre } 2p+1 \label{subeqCBQooTZGxQpsin}\\
      \ln(1+x)&=\sum_{k=0}^{n-1}(-1)^k\frac{ x^{k+1} }{ k+1 }+x^n\alpha(x)&\text{ordre } n\\
      (1+x)^l&=\sum_{k=0}^l\binom{ l }{ k }x^k&\text{exact si } l\text{ est entier.}\\
      (1+x)^{\alpha}&=1+\sum_{k=1}^n\frac{ \alpha(\alpha-1)\ldots(\alpha-k+1) }{ k! }x^k+x^n\alpha(x)&\text{ordre } n.\label{subEqJFNooQQodFQ}
    \end{align}
  \end{subequations}
\end{framed}
Il est fortement suggéré au lecteur de vérifier ces développements par lui-même.

\begin{remark}
  Quelque remarques.
  \begin{enumerate}
  \item
    Les développements de sinus et de cosinus ont un terme sur deux qui est nul. C'est pour cela qu'en ayant une polynôme de degré \( 2p\), nous avons le développement d'ordre \( 2p+1\).
  \item
    En ce qui concerne le développement de \( \ln(1+x)\), il faut noter que la somme va jusqu'à \( k=n-1\) (et non \( k=n\)) parce que nous voulons aller jusqu'à \( x^n\) et que nous écrivons \( x^{k+1}\).
  \item
    Si \( l\) est entier, le développement de \( (1+x)^l\) est exact. Dans le développement de \( (1+x)^{\alpha}\), nous reconnaissons la formule de \( \binom{ k }{\alpha }\), sauf que nous ne pouvons pas l'écrire avec cette notation lorsque \( \alpha\) n'est pas entier.
  \item Le développement limité en $0$ d'une fonction paire ne contient que les puissances de $x$ d'exposant paire. Voir comme exemple le développement de la fonction cosinus.
  \end{enumerate}
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Règles de calcul}
%---------------------------------------------------------------------------------------------------------------------------

Les règles suivantes permettent de calculer les développements limités des fonctions qu'on peut écrire comme combinaison des fonctions dans le tableau des équation s\eqref{SUBEQSooIFXBooIOkveI} de la section précédente. 
\begin{remark}
  Il est toujours possible de calculer le développement limité d'une fonction par la formule de Taylor-Young. Les règles suivantes peuvent nous economiser de l'effort et du temps. 
\end{remark}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Linéarité des développements limités}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

L'opération qui consiste à prendre le développement limité d'une fonction est une opération linéaire : connaissant les développements limités de \( f\) et de \( g\), il suffit de les sommer pour obtenir celui de \( f+g\). De m\^eme, si $\lambda$ est une constante, le développement limité de $\lambda f$ est le développement limité de $f$ fois $\lambda$. 
\begin{proposition}
Soient $\lambda$ et $\mu$ dans $\eR$.  Si \( f\) et \( g\) sont deux fonctions acceptant des développements limités d'ordre \( n\)
    \begin{subequations}    \label{EqJPPooCHihNn}
        \begin{align}
            f(x)&=P(x)+x^n\alpha_f(x)\\
            g(x)&=Q(x)+x^n\beta(x)
        \end{align}
    \end{subequations}
    avec \( \lim_{x\to 0} \alpha(x)=\lim_{x\to 0} \beta(x)=0\), alors la fonction \( \lambda f+\mu g\) admet le développement limité
    \begin{equation}    \label{EqCJFooVpyCtz}
        (f+g)(x)=(\lambda P+\mu Q)(x)+(\lambda \alpha+\mu\beta)(x).
    \end{equation}
\end{proposition}
\begin{remark}
  La forme explicite du reste ne nous interesse pas. Dans la pratique on écrira toujours $(f+g)(x)=(P+Q)(x)+\alpha(x)$, où on appelle $\alpha$ une fonction apportune telle que $\lim_{x\to 0} \alpha(x)=0$.
\end{remark}
\begin{proof}
    Vu les définitions \eqref{EqJPPooCHihNn} des polynômes \( P\), \( Q\) et des restes \( \alpha\) et \( \beta\), l'égalité \eqref{EqCJFooVpyCtz} est une conséquence de la linéarité de la dérivation et de la proposition \ref{PropVDGooCexFwy}

    De plus \( P+Q\) est un polynôme de degré \( n\) dès que \( P\) et \( Q\) sont des polynômes de degré \( n\), et
    \begin{equation}
        \lim_{x\to 0} (\lambda \alpha+\mu\beta)(x)=\lim_{x\to 0} \lambda\alpha(x)+\lim_{x\to 0} \mu\beta(x)=0.
    \end{equation}
    Par conséquent \(\lambda \alpha+\mu\beta\) est la fonction de reste de \( \lambda f+\mu g\).
\end{proof}

\begin{example} \label{ExKPBooJmdFvY}
    Calculer le développement de la fonction
    \begin{equation}
        f(x)=3\sqrt[3]{1+x}+ e^{-2x}.
    \end{equation}
    Le développement de \( \sqrt[3]{1+x}\) est donné par la formule \eqref{subEqJFNooQQodFQ} avec \( \alpha=\frac{1}{ 3 }\). Nous avons donc dans un premier temps
    \begin{subequations}
        \begin{align}
            \sqrt[3]{1+x}&=1+\frac{ 1 }{ 3 }x+\frac{ \frac{1}{ 3 }\left( \frac{1}{ 3 }-1 \right) }{ 2 }x^2+\frac{ \frac{1}{ 3 }\left( \frac{1}{ 3 }-1 \right)\left( \frac{1}{ 3 }-2 \right) }{ 6 }x^3+x^3\alpha(x)\\
            &=1+\frac{1}{ 3 }x-\frac{1}{ 9 }x^2+\frac{ 5 }{ 81 }x^3+x^3\alpha(x).
        \end{align}
    \end{subequations}
    Nous avons alors
    \begin{subequations}
        \begin{align}
            3\sqrt[3]{1+x}+ e^{-2x}&=3\Big[  1+\frac{1}{ 3 }x-\frac{1}{ 9 }x^2+\frac{ 5 }{ 81 }x^3+x^3\alpha(x)\Big]+1-2x+2x^2-\frac{ 4 }{ 3 }x^3+x^3\beta(x)\\
            &=4-x+\frac{ 5 }{ 3 }x^2-\frac{ 31 }{ 27 }x^3+x^3\big( \alpha(x)+\beta(x) \big).
        \end{align}
    \end{subequations}

\end{example}

La condition \( \lim_{x\to 0} \alpha(x)=0\) signifie que l'approximation qui consiste à remplacer \( f(x) \) par le polynôme n'est pas une trop mauvaise approximation lorsque \( x\) est petit. Cela ne signifie rien de plus. En particulier si \( x\) est grand, l'approximation polynômiale peut-être (et est souvent) très mauvaise.

À ce propos, notez qu'un polynôme tend toujours vers \( \pm\infty\) lorsque \( x\) est grand. Une approximation polynômiale d'une fonction bornée est donc toujours (très) mauvaise pour les grandes valeurs de \( x\).

À titre d'exemple nous avons tracé sur la figure \ref{LabelFigWUYooCISzeB} la fonction
\begin{equation}
    f(x)=3\sqrt[3]{x+1}+ e^{-2x}
\end{equation}
et ses développements limités d'ordre \( 1\) à \( 3\). Il est particulièrement visible que l'approximation est assez bonne pour la partie gauche du graphe sur laquelle la fonction est bien croissante, alors qu'elle est franchement mauvaise sur la droite où le graphe ressemble plutôt à une constante\footnote{Pouvez-vous cependant dire que vaut \( \lim_{x\to \infty} f(x)\) ?}.

\newcommand{\CaptionFigWUYooCISzeB}{Les développements limités d'ordre de plus en plus grand de la fonction de l'exemple \ref{ExKPBooJmdFvY}. La fonction est en bleu et les «approximations» sont en rouge.}
\input{auto/pictures_tex/Fig_WUYooCISzeB.pstricks}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Développement limité d'un quotient}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{proposition}
    Si \( P_f\) est le polynôme du développement limité de \( f\) à l'ordre \( n\) et \( P_g\) celui de \( g\), alors nous obtenons le développement limité de \( f/g\) à l'ordre \( n\) en effectuant la division selon les puissances croissantes de \( P_f\) par \( P_g\).
\end{proposition}
Attention : il s'agit bien de faire une division selon les puissances croissantes, et non une divisions euclidienne. La division euclidienne de \( A\) par \( B\) consiste à écrire \( A=BQ+R\) avec le reste \( R\) de degré le plus \emph{petit} possible. Ici nous voulons avoir un reste de degré le plus \emph{grand} possible.

\begin{example}
    Cherchons le développement limité à l'ordre \( 5\) de \( \tan(x)=\frac{ \sin(x) }{ \cos(x) }\). Nous utilisons les formules \eqref{subeqCBQooTZGxQpcos} et \eqref{subeqCBQooTZGxQpsin} pour savoir les développements de sinus et cosinus\footnote{Encore une fois, vous êtes très fortement encouragés à calculer vous-même ces développements à partir de la formule de Taylor-Young \ref{EQooBKZDooTqYyIB}.} :
    \begin{subequations}
        \begin{align}
            \sin(x)&=x-\frac{ x^3 }{ 6 }+\frac{ x^5 }{ 120 }+x^5\alpha_1(x)\\
            \cos(x)&=1-\frac{ x^2 }{ 2 }+\frac{ x^4 }{ 24 }+x^5\alpha_2(x).
        \end{align}
    \end{subequations}
    Nous calculons alors la division des deux polynômes, en classant les puissances dans l'ordre croissant (c'est le sens inverse de ce qui est fait pour la divisions euclidienne !) :
    \begin{equation*}
        \begin{array}[]{ccccccccccc|c}
            &x&-&\frac{1}{ 6 }x^3&+&\frac{1}{ 120 }x^5&&&&&&1-\frac{ 1 }{2}x^2+\frac{1}{ 24 }x^4\\
            \cline{12-12}
            -\Big( &x&-&\frac{ 1 }{2}x^3&+&\frac{1}{ 24 }x^5&\Big)& & && &x+\frac{1}{ 3 }x^3+\frac{ 2 }{ 15 }x^5\\
            \cline{2-6}
            & & &\frac{1}{ 3 }x^3&-&\frac{1}{ 30 }x^5& & & & && \\
            &&-\Big(  &\frac{1}{ 3 }x^3&-&\frac{1}{ 6 }x^5&+&\frac{1}{ 72 }x^7&\Big) & & \\
            \cline{4-8}
            & & & & &\frac{ 2 }{ 15 }x^5&-&\frac{1}{ 72 }x^7& & & \\
            & & &  &-\Big(  &\frac{ 2 }{ 15 }x^5&-&\frac{1}{ 15 }x^7&+&\frac{1}{ 180 }x^9&\Big)& \\
            \cline{6-10}
            & & & & & & &\frac{ 29 }{ 360 }x^7&-&\frac{1}{ 180 }x^9&& \\
        \end{array}
    \end{equation*}
    Nous avons continué la division jusqu'à obtenir un reste de degré plus grand que \( 5\). Le développement à l'ordre $5$ de la fonction tangente autour de zéro est alors
    \begin{equation}
        \tan(x)=x+\frac{1}{ 3 }x^3+\frac{ 2 }{ 15 }x^5+x^5\alpha(x).
    \end{equation}
    Notons que, vu que le reste ne nous intéresse pas vraiment, nous aurions pu ne pas calculer les coefficients des termes en \( x^7\) et \( x^8\). La dernière soustraction était également inutile.
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Développement limité d'une fonction composée}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


\begin{proposition}
    Soient \( f\) et \( g\) des fonctions admettant des développements limités d'ordre $n$ au voisinage de $0$. Nous supposons que \( \lim_{x\to 0} g(x)=0\). Alors la composée \( f\big( g(x) \big)\) admet un développement limité d'ordre $n$ au voisinage de $0$ qui s'obtient en substituant le développement de \( g\) à chaque <<\(x \)>> du développement de \( f\), et en supprimant tous les termes de degré plus élevé que $n$.
\end{proposition}

\begin{example}\label{compose1}
    Pour trouver le développement de la fonction \( f(x)= e^{-2x}\), il suffit d'écrire celui de \( e^t\) et de remplacer ensuite $t$ par \( -2x\). Le développement à l'ordre \( 3\) de la fonction exponentielle est :
    \begin{equation}
        e^t=1+t+\frac{ t^2 }{2}+\frac{ t^3 }{ 6 }+t^3\alpha(t).
    \end{equation}
    Le développement de \( f(x)= e^{-2x}\) sera donc 
    \begin{equation}
        f(x)=1-2x+\frac{ 4x^2 }{ 2 }-\frac{ 8x^3 }{ 6 }-8x^3\alpha(-2x).
    \end{equation}
    Donc le polynôme de degré \( 3\) partie régulière de \( g\) est :
    \begin{equation}
        1-2x+2x^2-\frac{ 4 }{ 3 }x^3,
    \end{equation}
    et la fonction reste correspondante est :
    \begin{equation}
        \alpha_g(x)=-8\alpha(-2x).
    \end{equation}
\end{example}

\begin{example}
    Nous savons les développements
    \begin{equation}
        f(x)=\ln(1+x)\sim x-\frac{ x^2 }{ 2 }+\frac{ x^3 }{ 3 }
    \end{equation}
    et
    \begin{equation}
        \sin(x)\sim x-\frac{ x^3 }{ 6 }.
    \end{equation}
    Nous obtenons le développement d'ordre \( 3\) de la fonction \( x\mapsto \ln\big( 1+\sin(x) \big)\) en écrivant
    \begin{equation}    \label{EqGXMooWKQkIL}
        \ln\big( 1+\sin(x) \big)\sim \big( x-\frac{ x^3 }{ 6 } \big)-\frac{ 1 }{2}\left( x-\frac{ x^3 }{ 6 } \right)^2+\frac{1}{ 3 }\left( x-\frac{ x^3 }{ 6 } \right)^3.
    \end{equation}
    Il s'agit maintenant de trouver les termes qui sont de degré inférieur ou égale à \( 3\).

    D'abord
    \begin{equation}
        \left( x-\frac{ x^3 }{ 6 } \right)^2=x^2-\frac{ x^4 }{ 3 }+\frac{ x^6 }{ 36 }\sim x^2
    \end{equation}
    Nous avons alors aussi
    \begin{equation}
        \left( x-\frac{ x^3 }{ 6 } \right)^6\sim x^2\left( x-\frac{ x^3 }{ 6 } \right)\sim x^3.
    \end{equation}
    En replaçant tout ça dans \eqref{EqGXMooWKQkIL} nous trouvons
    \begin{equation}
        \ln\big( 1+\sin(x) \big)\sim x-\frac{ x^2 }{2}+\frac{ x^3 }{ 6 }.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Développement au voisinage de $x_0\neq 0$}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Il est intéressant de développer une fonction au voisinage de zéro lorsque nous nous intéressons à son comportement pour les \( x\) pas très grands. Il est toutefois souvent souhaitable de savoir le comportement d'une fonction au voisinage d'autres valeurs que zéro.

Pour développer la fonction \( f\) autour de \( x_0\), nous considérons la fonction \( h\mapsto f(x_0+h)\) que nous développons autour de zéro (pour \( h\)). L'objectif est de trouver une polynôme \( P\) et une fonction \( \alpha\) tels que
\begin{subequations}
    \begin{numcases}{}
        f(x)=P(x)+(x-x_0)^n\alpha(x)\\
        \lim_{x\to x_0} \alpha(x)=0.
    \end{numcases}
\end{subequations}
En pratique, le développement limité à l'ordre $n$ d'une fonction autour d'un point $x_0$ quelconque à l'intérieur de son domaine prend la forme suivante, qui généralise la formule de Taylor-Young vue dans la proposition \ref{PropVDGooCexFwy}
\begin{proposition}[Formule de Taylor-Young, cas général]    
    Soit \( f\) une fonction \( n\) fois dérivable sur un intervalle \( I\) contenant \(x_0\). Alors il existe une fonction \( \alpha\colon I\to \eR\) telle que
    \begin{equation}    \label{EqTJRooUbsyzJ}
      \begin{aligned}
        f(x)=f(x_0)+&f'(x_0)(x-x_0)+\frac{ f''(x_0) }{ 2 }(x-x_0)^2+\\
        &+\frac{ f^{(3)}(x_0) }{ 3! }(x-x_0)^3+\cdots +\frac{ f^{(n)}(x_0) }{ n! }(x-x_0)^n+(x-x_0)^n\alpha(x-x_0)
      \end{aligned}
    \end{equation}
    et
    \begin{equation}
        \lim_{t\to 0} \alpha(t)=0.
    \end{equation}
  
\end{proposition}
\begin{example}\label{developcosenpisur3}
    Développer la fonction \( \cos\) autour de \( x=\frac{ \pi }{ 3 }\). Nous développons autour de \( h=0\) la fonction \( \cos(\frac{ \pi }{ 3 }+h)\) :
    \begin{equation}
        \cos\big( \frac{ \pi }{ 3 }+h \big)\sim \cos\big( \frac{ \pi }{ 3 } \big)+h\cos'(\frac{ \pi }{ 3 })+\frac{ h^2 }{2}\cos''\big( \frac{ \pi }{ 3 } \big)=\frac{ 1 }{2}-\frac{ \sqrt{3} }{2}h-\frac{1}{ 4 }h^2.
    \end{equation}
    Il est aussi possible d'écrire cela en notant \( x=x_0+h\), c'est à dire en remplaçant \( h\) par \( x-\frac{ \pi }{ 3 }\) :
    \begin{equation}
        \cos(x)\sim\frac{ 1 }{2}-\frac{ \sqrt{3} }{ 2 }(x-\frac{ \pi }{ 3 })-\frac{1}{ 4 }(x-\frac{ \pi }{ 3 })^2.
    \end{equation}
\end{example}

Pour donner une idée nous avons dessiné sur le graphe suivant la fonction sinus et ses développements d'ordre \( 4\) autour de zéro et autour de \( 3\pi/4\).
\begin{center}
   \input{auto/pictures_tex/Fig_WJBooMTAhtl.pstricks}
\end{center}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Application au calcul de limites}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Lors d'un calcul de limite, développer une partie d'une expression peut être utile.

\begin{example}
    À calculer :
    \begin{equation}
        \lim_{x\to 0} \frac{ \ln(1+x) }{ x }.
    \end{equation}
    Cela est une indétermination de type \( \frac{ 0 }{ 0 }\). Le développement limité du numérateur nous donne une fonction \( \alpha(x)\) telle que \( \lim_{x\to 0} \alpha(x)=0\) et
    \begin{equation}
        \frac{ \ln(1+x) }{ x }=\frac{ x-\frac{ x^2 }{2}+x^2\alpha(x) }{ x }=1-\frac{ x }{ 2 }+x\alpha(x).
    \end{equation}
    Sur le membre de droite la limite est facile à calculer :
    \begin{equation}
        \lim_{x\to 0} \frac{ \ln(1+x) }{ x }=\lim_{x\to 0} \Big( 1-\frac{ x }{ 2 }+x\alpha(x) \Big) =1.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Développement au voisinage de l'infini}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Il est souvent utile de connaître le comportement d'une fonction pour les grandes valeurs de \( x\) et de déterminer ses asymptotes éventuelles. La technique que nous allons utiliser consiste à poser \( x=\frac{1}{ h }\) et de développer la fonction ``auxiliaire'' $g(h) = f(1/h)$ autour de \( h=0\). La limite avec \( h\to 0^+\) donnera le comportement pour \( x\to \infty\) et la limite \( h\to 0^-\) donnera le comportement pour \( x\to -\infty\).

Dans le cas d'une développement autour de \( \pm\infty\) nous ne parlons plus de développement \emph{limité} mais de \defe{développement asymptotique}{développement!asymptotique}.

\begin{example}	\label{ExBCDookjljhjk}
    Calculer
    \begin{equation}\label{EqABCoolkjh}
        \lim_{x\to \infty}  e^{1/x}\sqrt{1+4x^2}-2x.
    \end{equation}
    Nous allons effectuer un développement asymptotique de la partie «difficile» de l'expression posant d'abord $x=1/h$. Si $f(x)=e^{1/x}\sqrt{1-4x^2}$ alors
    \begin{equation}
	g(h)=\frac{1}{|h|}e^h\sqrt{h^2+4}=\frac{1}{h}\big(  1+h+h\alpha(h) \big)\big( 2+h\beta(h) \big).
    \end{equation}
    La première parenthèse est le développement de $e^h$ et la seconde celui de $\sqrt{h^2+4}$. Nous nous apprêtons à faire la limite $x\to\infty$ qui correspond à $h\to 0^+$, nous pouvons donc supposer que $h>0$ et omettre la valeur absolue. En effectuant le produit et en regroupant tous les termes contenant $h^2$, $\alpha(h)$ ou $\beta(h)$ dans un seul terme $h\gamma(h)$,
    \begin{equation}
	f(h)=\frac{1}{h}\big(  2+2h+h\gamma(h) \big)=\frac{2}{h}+2+\gamma(h)=2x+2+\gamma(1/x)
    \end{equation}
    où $\gamma$ est une fonction vérifiant $\lim_{t\to 0}\gamma(t)=0$.

    Nous sommes maintenant en mesure de calculer la limite \eqref{EqABCoolkjh} :
    \begin{equation}
	\lim_{x\to\infty}e^{1/x}\sqrt{1+x^2}-2x= \lim_{x\to \infty}\big(  2x+2+\gamma(1/x)-2x \big)=2.
    \end{equation}
\end{example}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Étude d'asymptote}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Lorsqu'une fonction tend vers l'infini pour \( x\to \infty\), une question qui peut venir est : à quelle vitesse tend-t-elle vers l'infini ?

Il est «visible» que la fonction logarithme ne tend pas très vite vers l'infini : certes
\begin{equation}
    \lim_{x\to \infty} \ln(x)=+\infty,
\end{equation}
mais par exemple \( \ln(100000)\simeq 11.5\) tandis que \(  e^{100000}\simeq 10^{43429}\). Sans contestations possibles, l'exponentielle croit plus vite que le logarithme.

Soient \( f\) et \( g\) deux fonctions dont la limite \( x\to \infty\) est \( \infty\). Si
\begin{equation}
    \lim_{x\to \infty} \frac{ f(x) }{ g(x) }=0
\end{equation}
nous disons que \( g\) tend vers \( \infty\) plus vite que \( f\); si
\begin{equation}
    \lim_{x\to \infty} \frac{ f(x) }{ g(x) }=\infty
\end{equation}
nous disons que \( f\) tend vers \( \infty\) plus vite que \( g\), et si
\begin{equation}
    \lim_{x\to \infty} \frac{ f(x) }{ g(x) }=a\in \eR
\end{equation}
avec \( a\neq 0\) alors nous disons que \( f\) tend vers l'infini à la même vitesse que \( ag(x)\).

\begin{example}
    La fonction \( x\mapsto x^2\) tend vers l'infini plus vite que la fonction \( x\mapsto \sqrt{x}\).
\end{example}

Dans cette section nous allons nous contenter de déterminer les fonctions qui tendent vers l'infini aussi vite qu'une droite oblique, que nous appellons asymptote et que nous voulons déterminer.


\begin{example}
    Déterminer les asymptotes obliques (s'ils existent) de la fonction
    \begin{equation}
        f(x)= e^{1/x}\sqrt{1+4x^2}.
    \end{equation}
    Tout d'abord nous remarquons que \( \lim_{x\to \infty} f(x)=\infty\). Nous sommes donc en présence d'une branche du graphe qui tend vers l'infini. Ensuite,
    \begin{equation}
        \lim_{x\to \infty} \frac{ f(x) }{ x }=\lim_{x\to \infty}  e^{1/x}\sqrt{\frac{1}{ x^2 }+4}=2.
    \end{equation}
    Donc le graphe de \( f\) tend vers l'infini à la même vitesse que le graphe de la fonction \( y=2x\). Nous aurons donc une asymptote oblique de coefficient directeur \( 2\). De façon imagée, nous pouvons penser que le graphe de \( f\) et celui de \( y=2x\) sont presque parallèles si \( x\) est assez grand. Afin de déterminer l'ordonnée à l'origine de l'asymptote, il nous reste à voir quelle est la «distance» entre le graphe de \( f\) et celui de \( y=2x\) :
    \begin{equation}
        \lim_{x\to \infty} f(x)-2x=\lim_{x\to \infty}  e^{1/x}\sqrt{1+4x^2}-2x.
    \end{equation}
    Cette limite a été calculée dans l'exemple \ref{ExBCDookjljhjk} et vaut $2$.

	Nous concluons que le graphe de la fonction $f$ admet l'asymptote
    \begin{equation}
	y=2x+2.
    \end{equation}
\end{example}
